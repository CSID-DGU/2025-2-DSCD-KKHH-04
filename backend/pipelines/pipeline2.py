# -*- coding: utf-8 -*-
"""
ì„œë²„ìš© íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ

ê¸°ëŠ¥:
- WAV/WEBM ë“± ìŒì„± íŒŒì¼ â†’ STT(openai-whisper)
- STT í…ìŠ¤íŠ¸ â†’ ê¸€ë¡œìŠ¤ ì¶”ì¶œ(Gemini or ë¡œì»¬ ê·œì¹™)
- ê¸€ë¡œìŠ¤ â†’ gloss_id ë§¤í•‘(CSV ì‚¬ì „)
- gloss_id â†’ ìˆ˜ì–´ ì˜ìƒ(mp4) ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

Djangoì—ì„œëŠ”:
    from pipelines.pipeline import (
        stt_from_file,
        extract_glosses,
        to_gloss_ids,
        load_gloss_index,
        _paths_from_ids,
        build_gemini,
        MEDIA_ROOT,
        now_ts,
    )

ê°™ì€ ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì„œ ì‚¬ìš©í•˜ë©´ ëœë‹¤.
"""

import os
import csv
import re
import json
import ast
import unicodedata
import difflib
import time
import sys
from datetime import datetime
from pathlib import Path
import shutil
import subprocess
import wave  # WAV ê¸¸ì´(ì´ˆ) ê³„ì‚°ìš©

import whisper  # openai-whisper

# Gemini â€“ ì—†ìœ¼ë©´ ë¡œì»¬ ê·œì¹™ìœ¼ë¡œë§Œ ê¸€ë¡œìŠ¤ ì¶”ì¶œ
try:
    import google.generativeai as genai
except Exception:
    genai = None
    gexc = None

# =========================================================
# ì „ì—­ ê²½ë¡œ/í™˜ê²½ ì„¤ì •
# =========================================================

# pipeline.py ìœ„ì¹˜:
#   C:\...\backend\pipelines\pipeline.py
PIPELINE_DIR = Path(__file__).resolve().parent       # backend/pipelines
ROOT_DIR = PIPELINE_DIR.parent                       # backend

# Django MEDIA_ROOTì™€ ë§ì¶°ë‘ëŠ” ìš©ë„ (í•„ìš”í•˜ë©´ settingsì™€ ë§ì¶”ë©´ ë¨)
MEDIA_ROOT = ROOT_DIR / "media"

# ë°ì´í„°/ì˜ìƒ í´ë” (ë„¤ ì‹¤ì œ êµ¬ì¡°ì— ë§ì¶¤)
DATA_DIR = ROOT_DIR / "data"

# ë„ˆê°€ ì‹¤ì œë¡œ ê°€ì§€ê³  ìˆëŠ” íŒŒì¼ ê¸°ì¤€
#   C:\...\backend\data\gloss_dictionary_MOCK_1.csv
GLOSS_INDEX_PATH = DATA_DIR / "gloss_dictionary_MOCK_1.csv"

#   C:\...\backend\pipelines\gloss_mp4\100123.mp4 ...
SIGN_VID_DIR = MEDIA_ROOT / "sign_videos"
SIGN_VID_DIR.mkdir(parents=True, exist_ok=True)

# ìŠ¤ëƒ…ìƒ·/ë¡œê·¸ í´ë”ë“¤
SNAPSHOT_DIR = ROOT_DIR / "snapshots"
SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)

OUT_DIR = SNAPSHOT_DIR / "local"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# delta ìš© í´ë”ëŠ” í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# OUT_DIR_DELTA = SNAPSHOT_DIR / "delta_backend"
# OUT_DIR_DELTA.mkdir(parents=True, exist_ok=True)

OUT_JSON_DIR = SNAPSHOT_DIR / "json"
OUT_JSON_DIR.mkdir(parents=True, exist_ok=True)

# STT / Gemini ì„¤ì •
GOOGLE_API_KEY     = os.environ.get("GOOGLE_API_KEY", "")  # ì—†ìœ¼ë©´ Gemini ë¯¸ì‚¬ìš©
GEMINI_MODEL_NAME  = "models/gemini-2.5-flash"
WHISPER_MODEL_NAME = "small"
WHISPER_LANG       = "ko"


def now_ts():
    """ë¡œê·¸/íŒŒì¼ëª…ì— ì“°ê¸° ì¢‹ì€ íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


# =========================================================
# ì •ê·œí™” / ìœ í‹¸
# =========================================================

def _normalize_korean(text: str) -> str:
    """í•œê¸€ ì •ê·œí™”: NFKC, ê³µë°± ì •ë¦¬ ë“±."""
    text = unicodedata.normalize("NFKC", text)
    text = text.replace("\u3000", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()


def _norm(text: str) -> str:
    if not text:
        return ""
    text = _normalize_korean(text)
    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±° ì˜ˆì‹œ
    text = re.sub(r'[â€œâ€\""]', "", text)
    return text.strip()


def safe_json_loads(s, default=None):
    try:
        return json.loads(s)
    except Exception:
        try:
            return ast.literal_eval(s)
        except Exception:
            return default


def get_wav_duration_sec(file_path: str):
    """
    WAV íŒŒì¼ ê¸¸ì´(ì´ˆ)ë¥¼ ëŒ€ëµ ê³„ì‚°.
    - whisperì— ë„£ëŠ” ì…ë ¥ì´ ë³´í†µ wavë¼ê³  ê°€ì •
    """
    try:
        with wave.open(file_path, "rb") as wf:
            frames = wf.getnframes()
            rate = wf.getframerate() or 16000
            return round(frames / float(rate), 3)
    except Exception as e:
        print(f"[WARN] get_wav_duration_sec ì‹¤íŒ¨: {e}")
        return None


# =========================================================
# Whisper STT ë¡œë”©
# =========================================================

print(f"[Whisper] loading model: {WHISPER_MODEL_NAME}")
STT_MODEL = whisper.load_model(WHISPER_MODEL_NAME, device="cpu")



def stt_from_file(file_path: str) -> str:
    """
    ì£¼ì–´ì§„ ìŒì„± íŒŒì¼ ê²½ë¡œ ì „ì²´ì—ì„œ STT ì‹¤í–‰ í›„ ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ë°˜í™˜.
    (ì•, ë’¤, ì¤‘ê°„ í¬í•¨ ì „ì²´ ì „ì‚¬)
    """
    result = STT_MODEL.transcribe(
        file_path,
        language=WHISPER_LANG,
        fp16=False,          # ğŸ”¹ CPUì—ì„œëŠ” í•­ìƒ False
    )
    text = result.get("text") or ""
    return _norm(text)


# =========================================================
# Gemini ë¹Œë“œ
# =========================================================

def build_gemini():
    """í™˜ê²½ë³€ìˆ˜ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¤€ë¹„ë˜ë©´ Gemini ëª¨ë¸ì„ ìƒì„±, ì•„ë‹ˆë©´ None."""

    if genai is None:
        print("[Gemini] generativeai ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ â†’ ë¡œì»¬ ê·œì¹™ë§Œ ì‚¬ìš©")
        return None

    if not GOOGLE_API_KEY:
        print("[Gemini] GOOGLE_API_KEY ì—†ìŒ â†’ ë¡œì»¬ ê·œì¹™ë§Œ ì‚¬ìš©")
        return None

    # API í‚¤ ì„¤ì •
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
    except Exception as e:
        print(f"[Gemini] API í‚¤ ì„¤ì • ì‹¤íŒ¨: {e}")
        return None

    sys_prompt = (
        "ì—­í• : í•œêµ­ì–´ ì „ì‚¬ êµì • + ìˆ˜ì–´ ê¸€ë¡œìŠ¤ ì¶”ì¶œê¸°.\n"
        'ì¶œë ¥ í˜•ì‹: {"clean":"â€¦","gloss":["â€¦"]} â€” JSON í•œ ì¤„ë§Œ.\n'
        "ê·œì¹™:\n"
        "1) clean: ì›ë¬¸ì˜ ì˜ë¯¸ë¥¼ ë³´ì¡´í•´ ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥ìœ¼ë¡œ êµì •.\n"
        "2) gloss: ë°˜ë“œì‹œ í•œêµ­ì–´ ë‹¨ì–´ 1ê°œ(ê³µë°± ê¸ˆì§€)ë“¤ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸.\n"
        "   - ì¡°ì‚¬/ì–´ë¯¸/ì ‘ì‚¬ ê¸ˆì§€(ì˜ˆ: 'ëŒ€ìƒì—ëŠ”' âœ— â†’ 'ëŒ€ìƒ' âœ“)\n"
        "   - í‘œì œí˜•/ëª…ì‚¬í˜•ìœ¼ë¡œ ì ê¸°('ë³´í˜¸í•˜ë‹¤' âœ— â†’ 'ë³´í˜¸' âœ“)\n"
        "   - ìˆ«ìÂ·ë‹¨ìœ„ëŠ” ê²°í•© í‘œê¸° í—ˆìš©(ì˜ˆ: 1ì–µì›, 6ê°œì›”, 5ë…„)\n"
        "   - ì˜ë¯¸ë¥¼ í¬ê´„í•˜ë˜ ì¤‘ë³µ ì—†ì´ 1â€“10ê°œ ë²”ìœ„ë¡œ ì‚°ì¶œ.\n"
        "3) ì˜ˆì‹œ:\n"
        '   ì…ë ¥: "ê°€ì… ëŒ€ìƒì—ëŠ” ì œí•œì´ ì—†ìœ¼ë©° ëˆ„êµ¬ë‚˜ ê°€ì… ê°€ëŠ¥í•©ë‹ˆë‹¤."\n'
        '   gloss: ["ê°€ì…","ëŒ€ìƒ","ì œí•œ","ê°€ëŠ¥"]\n'
        '   ì…ë ¥: "ì´ ìƒí’ˆì€ ì˜ˆê¸ˆìë³´í˜¸ë²•ì— ë”°ë¼ ì›ê¸ˆê³¼ ì´ìë¥¼ í•©í•˜ì—¬ 1ì¸ë‹¹ 1ì–µì›ê¹Œì§€ ë³´í˜¸ë©ë‹ˆë‹¤."\n'
        '   gloss: ["ìƒí’ˆ","ì˜ˆê¸ˆìë³´í˜¸ë²•","ì›ê¸ˆ","ì´ì","1ì¸ë‹¹","1ì–µì›","ë³´í˜¸"]\n'
    )

    try:
        model = genai.GenerativeModel(
            GEMINI_MODEL_NAME,
            system_instruction=sys_prompt,
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.2,
            },
        )
        print(f"[Gemini] ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: {GEMINI_MODEL_NAME}")
        return model

    except Exception as e:
        print(f"[Gemini] ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


GEMINI_MODEL = build_gemini()


# =========================================================
# ê¸€ë¡œìŠ¤ ì¸ë±ìŠ¤ ë¡œë”©
# =========================================================

def load_gloss_index(path: Path = None):
    """
    gloss_dictionary_MOCK_1.csvë¥¼ ì½ì–´ì„œ
    { "í†µì¥": "104886", "í† ë¼": "104887", ... } í˜•íƒœì˜ dictë¥¼ ë§Œë“ ë‹¤.

    CSV í—¤ë”:
      gloss_id,korean_meanings,cat_1,cat_2,cat_3,original_vd_idx,source
    ì˜ˆì‹œ í–‰:
      104886,['í†µì¥'],ì¼ìƒìƒí™œ ìˆ˜ì–´,,,505,li
    """
    p = path or GLOSS_INDEX_PATH
    idx = {}

    if not p.exists():
        print(f"[GlossIndex] íŒŒì¼ ì—†ìŒ: {p}")
        return idx

    with open(p, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        print(f"[GlossIndex] í—¤ë”: {reader.fieldnames}")

        for row in reader:
            # 1) ì–´ë–¤ IDë¥¼ ì“¸ì§€ ì„ íƒ
            #   - gloss_id = "104886"
            #   - original_vd_idx = "505"
            # mp4 íŒŒì¼ ì´ë¦„ì´ gloss_id ê¸°ì¤€ì´ë©´ ì•„ë˜ì²˜ëŸ¼ gloss_id ì‚¬ìš©
            gid = (row.get("gloss_id") or "").strip()

            # ë§Œì•½ mp4ê°€ 505.mp4 í˜•ì‹ì´ë©´ ì•„ë˜ ì¤„ë¡œ ë°”ê¿”:
            # gid = (row.get("original_vd_idx") or "").strip()

            # 2) korean_meanings íŒŒì‹±: "['í†µì¥']" â†’ ["í†µì¥"]
            raw_meanings = row.get("korean_meanings", "")
            meanings = safe_json_loads(raw_meanings, default=None)

            tokens = []
            if isinstance(meanings, list):
                # ['í†µì¥'] ë˜ëŠ” ['ì •ê¸°ì˜ˆê¸ˆ', 'ì ê¸ˆ'] ì´ëŸ° ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ
                for m in meanings:
                    t = _norm(str(m))
                    if t:
                        tokens.append(t)
            else:
                # í˜¹ì‹œ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±ì´ ì•ˆ ë˜ë©´, ê·¸ëƒ¥ ë¬¸ìì—´ í•˜ë‚˜ë¡œ ì²˜ë¦¬
                t = _norm(str(raw_meanings))
                if t:
                    tokens.append(t)

            # 3) í† í°ë“¤ â†’ gid ë§¤í•‘
            for t in tokens:
                if t and gid:
                    idx[t] = gid

    print(f"[GlossIndex] ë¡œë”© ì™„ë£Œ: {len(idx)}ê°œ, from {p}")
    sample = list(idx.items())[:10]
    print(f"[GlossIndex] ì˜ˆì‹œ ëª‡ ê°œ: {sample}")
    return idx


GLOSS_INDEX = load_gloss_index()


# =========================================================
# ê¸€ë¡œìŠ¤ â†’ ID ë§¤í•‘ ë° ì˜ìƒ ê²½ë¡œ ìƒì„±
# =========================================================

def _paths_from_ids(gloss_ids):
    """
    gloss_id ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ì¡´ì¬í•˜ëŠ” mp4 ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    - backend/pipelines/gloss_mp4/<gloss_id>.mp4
    """
    paths = []
    for gid in gloss_ids:
        p = SIGN_VID_DIR / f"{gid}.mp4"
        if p.exists():
            paths.append(str(p))
        else:
            print(f"[WARN] gloss_id {gid}ì— í•´ë‹¹í•˜ëŠ” ì˜ìƒ ì—†ìŒ: {p}")
    return paths


def to_gloss_ids(gloss_list, gloss_index=None):
    """
    ê¸€ë¡œìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ gloss_id ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    - exact match ìš°ì„ 
    - ì‹¤íŒ¨ ì‹œ ìœ ì‚¬ë„ ê¸°ë°˜ fallback (difflib)
    """
    idx = gloss_index or GLOSS_INDEX
    ids = []

    for token in gloss_list:
        t = _norm(token)
        if not t:
            continue

        if t in idx:
            ids.append(idx[t])
            continue

        # fallback: ë¹„ìŠ·í•œ í‚¤ ì°¾ê¸°
        # candidates = difflib.get_close_matches(t, idx.keys(), n=1, cutoff=0.8)
        candidates = difflib.get_close_matches(t, idx.keys(), n=1)
        if candidates:
            m = candidates[0]
            print(f"[Fallback] '{t}' â†’ '{m}' ë§¤í•‘ ì‚¬ìš©")
            ids.append(idx[m])
        else:
            print(f"[UnknownGloss] '{t}' ë§¤í•‘ ì‹¤íŒ¨")
    return ids


# =========================================================
# ê¸€ë¡œìŠ¤ ì¶”ì¶œ (STT í…ìŠ¤íŠ¸ â†’ gloss list)
# =========================================================

def _local_gloss_rules(text: str):
    """
    Geminië¥¼ ì“°ì§€ ëª»í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë‹¨ìˆœ ë¡œì»¬ ê·œì¹™.
    ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ë„ë©”ì¸ ê·œì¹™/í† í¬ë‚˜ì´ì €ë¡œ ëŒ€ì²´í•˜ë©´ ë¨.
    """
    text = _norm(text)
    if not text:
        return []

    # ë§¤ìš° ë‹¨ìˆœí•œ ì˜ˆ: ê³µë°± ê¸°ì¤€ í† í° ë¶„ë¦¬
    tokens = re.split(r"[ ,.!?]+", text)
    tokens = [t for t in tokens if t]
    return tokens


def extract_glosses(text: str, gemini_model=None):
    """
    STT í…ìŠ¤íŠ¸ì—ì„œ gloss ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ.
    - gemini_model ìˆìœ¼ë©´ LLM ê¸°ë°˜ íŒŒì‹±
    - ì—†ìœ¼ë©´ ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ ë¶„ë¦¬
    """
    model = gemini_model or GEMINI_MODEL

    if not model:
        return _local_gloss_rules(text)

    prompt = f"""
ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ˜ì–´ ê¸€ë¡œìŠ¤ í˜•íƒœì˜ 'í† í° ë¦¬ìŠ¤íŠ¸'ë¡œ ë§Œë“¤ì–´ì¤˜.
- ë¶ˆí•„ìš”í•œ ì¡°ì‚¬/ì–´ë¯¸ëŠ” ì œê±°
- í•µì‹¬ ì˜ë¯¸ ë‹¨ì–´ ìœ„ì£¼ë¡œ ë‹¨ì–´ ì‚¬ì´ë¥¼ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„
- ì¶œë ¥ì€ JSON ë°°ì—´ í˜•ì‹ë§Œ ì‚¬ìš© (ì˜ˆ: ["ê¸°ê°„", "ìµœì†Œ", "1ë…„"])

ë¬¸ì¥: "{text}"
"""
    try:
        resp = model.generate_content(prompt)
        raw = resp.text.strip()
        gloss_list = safe_json_loads(raw, default=None)
        if isinstance(gloss_list, list):
            return [_norm(str(t)) for t in gloss_list if str(t).strip()]
        else:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ê·¸ëƒ¥ ë¡œì»¬ ê·œì¹™ fall back
            return _local_gloss_rules(text)
    except Exception as e:
        print(f"[Gemini.extract_glosses] ì˜¤ë¥˜: {e}")
        return _local_gloss_rules(text)


# =========================================================
# ë¬¸ì¥ ë‹¨ìœ„ íŒŒì´í”„ë¼ì¸ (íŒŒì¼ ì…ë ¥)
# =========================================================

def run_full_pipeline_on_file(file_path: str):
    """
    í•œ ë²ˆì—:
    - ìŒì„± íŒŒì¼ ì „ì²´ â†’ STT
    - STT í…ìŠ¤íŠ¸ â†’ gloss ë¦¬ìŠ¤íŠ¸
    - gloss ë¦¬ìŠ¤íŠ¸ â†’ gloss_id ë¦¬ìŠ¤íŠ¸
    - gloss_id â†’ ì˜ìƒ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    ê²°ê³¼(dict)ë¥¼ ë°˜í™˜.
    """
    # 1) íŒŒì¼ ê¸¸ì´(ì´ˆ) ê³„ì‚° (wav ê¸°ì¤€)
    audio_sec = get_wav_duration_sec(file_path)

    # 2) STT ì‹œê°„ ì¸¡ì •
    t0 = time.perf_counter()
    stt_text = stt_from_file(file_path)
    t1 = time.perf_counter()

    stt_ms = round((t1 - t0) * 1000, 1)

    # 3) ì½˜ì†” ë¡œê·¸: ê¸¸ì´ vs STT ì‹œê°„
    if audio_sec is not None:
        ratio = stt_ms / audio_sec if audio_sec > 0 else stt_ms
        print(
            f"[STT Timing] file={file_path} | "
            f"audio_sec={audio_sec} s | stt_ms={stt_ms} ms "
            f"({ratio:.1f} ms/sec)"
        )
    else:
        print(f"[STT Timing] file={file_path} | audio_sec=? | stt_ms={stt_ms} ms")

    # 4) NLP / ë§¤í•‘ / ê²½ë¡œ ìƒì„±
    t_nlp0 = time.perf_counter()
    gloss_list = extract_glosses(stt_text, GEMINI_MODEL)
    t_nlp1 = time.perf_counter()

    t_map0 = time.perf_counter()
    gloss_ids = to_gloss_ids(gloss_list, GLOSS_INDEX)
    paths = _paths_from_ids(gloss_ids)
    t_map1 = time.perf_counter()

    return {
        "input_file": file_path,
        "audio_sec": audio_sec,          # ê¸¸ì´ ì •ë³´ë„ í¬í•¨
        "stt_text": stt_text,
        "gloss": gloss_list,
        "gloss_ids": gloss_ids,
        "paths": paths,
        "latency_ms": {
            "total": round((t_map1 - t0) * 1000, 1),
            "stt": stt_ms,
            "nlp": round((t_nlp1 - t_nlp0) * 1000, 1),
            "mapping": round((t_map1 - t_map0) * 1000, 1),
        },
    }

# =========================================================
# (ì„ íƒ) ffmpegë¡œ ë¬¸ì¥ ì˜ìƒ í•©ì¹˜ê¸°
# =========================================================

def concat_videos_ffmpeg(video_paths, out_path: Path):
    """
    ì—¬ëŸ¬ ê°œ ìˆ˜ì–´ mp4 íŒŒì¼ì„ ffmpegë¡œ í•˜ë‚˜ì˜ ë¬¸ì¥ ì˜ìƒìœ¼ë¡œ í•©ì¹œë‹¤.
    video_paths: ì ˆëŒ€ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    out_path: ì¶œë ¥ mp4 ê²½ë¡œ
    """
    if not video_paths:
        raise ValueError("video_paths ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ")

    out_path = Path(out_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # ffmpeg concatìš© ì„ì‹œ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    list_file = out_path.with_suffix(".txt")
    with open(list_file, "w", encoding="utf-8") as f:
        for p in video_paths:
            f.write(f"file '{p}'\n")

    cmd = [
        "ffmpeg",
        "-y",
        "-f",
        "concat",
        "-safe",
        "0",
        "-i",
        str(list_file),
        "-c",
        "copy",
        str(out_path),
    ]

    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"[FFmpeg] concat ì™„ë£Œ â†’ {out_path}")
    except subprocess.CalledProcessError as e:
        print(f"[FFmpeg] ì˜¤ë¥˜: {e.stderr.decode('utf-8', errors='ignore')}")
        raise
    finally:
        if list_file.exists():
            list_file.unlink(missing_ok=True)

    return str(out_path)


# =========================================================
# 7) ì‹¤ì‹œê°„ ì„±ëŠ¥í‰ê°€ìš© delta íŒŒì´í”„ë¼ì¸ (í˜„ì¬ ë¯¸ì‚¬ìš©, ì „ì²´ ì£¼ì„ ì²˜ë¦¬)
# =========================================================

# DEBOUNCE_SEC = 1.0
# ACTUAL_RATE = 16000  # 16kHz, 16bit PCM ê¸°ì¤€ (len(blob)/(rate*2)ë¡œ ê¸¸ì´ ê³„ì‚°)
#
#
# def main():
#     """
#     ì‹¤ì‹œê°„ delta ìŒì„± ì…ë ¥ ê¸°ë°˜ ì„±ëŠ¥í‰ê°€ ëª¨ë“œ.
#     - Enter ì…ë ¥ ì‹œ delta blob ì¶”ì¶œ
#     - STT â†’ gloss â†’ gloss_id â†’ json ë¡œê·¸ ì €ì¥
#
#     ì£¼ì˜:
#     - pipelines/local_delta.py ì— cut_delta_blob(), play_sequence() êµ¬í˜„ í•„ìš”
#     - cut_delta_blob() â†’ bytes (raw wav blob)
#     - play_sequence(paths) â†’ gloss ì˜ìƒ ë¦¬ìŠ¤íŠ¸ ì¬ìƒ
#     """
#
#     from pipelines.local_delta import cut_delta_blob, play_sequence
#
#     snap = 0
#     last_trigger = 0.0
#
#     print("\n[Delta Pipeline Ready]")
#     print("[Enter] í‚¤ë¥¼ ëˆ„ë¥´ë©´ delta êµ¬ê°„ì„ ì „ì‚¬í•©ë‹ˆë‹¤.\n")
#
#     while True:
#         try:
#             input("\n[Enter] ì „ì‚¬ ì‹œì‘ ")
#
#             now = time.time()
#             if now - last_trigger < DEBOUNCE_SEC:
#                 continue
#             last_trigger = now
#
#             t_all0 = time.perf_counter()
#
#             blob = cut_delta_blob()
#             if not blob:
#                 print("[Info] ìƒˆ ì˜¤ë””ì˜¤ ì—†ìŒ.")
#                 continue
#
#             ts = now_ts()
#             base = OUT_DIR_DELTA / f"snapshot_{ts}_{snap+1:02d}"
#
#             wav_path = str(base) + ".wav"
#             with open(wav_path, "wb") as wf:
#                 wf.write(blob)
#
#             dur = len(blob) / (ACTUAL_RATE * 2)
#             print(f"[WAV] {wav_path} ({dur:.2f}s)")
#
#             t_stt0 = time.perf_counter()
#             res = STT_MODEL.transcribe(wav_path, language=WHISPER_LANG)
#             stt = _norm(res.get("text") or "")
#             stt_ms = round((time.perf_counter() - t_stt0) * 1000, 1)
#
#             txt_path = str(base) + ".txt"
#             with open(txt_path, "w", encoding="utf-8") as f:
#                 f.write(stt + "\n")
#
#             print(f"[STT] {stt_ms} ms â†’ {txt_path}")
#
#             t_nlp0 = time.perf_counter()
#             gloss_list = extract_glosses(stt, GEMINI_MODEL)
#             nlp_ms = round((time.perf_counter() - t_nlp0) * 1000, 1)
#
#             t_map0 = time.perf_counter()
#             gloss_ids = to_gloss_ids(gloss_list, GLOSS_INDEX)
#             paths = _paths_from_ids(gloss_ids)
#             map_ms = round((time.perf_counter() - t_map0) * 1000, 1)
#
#             print("[GLOSS]", gloss_list)
#             print("[GLOSS_ID]", gloss_ids)
#
#             t_vid0 = time.perf_counter()
#             play_sequence(paths)
#             video_ms = round((time.perf_counter() - t_vid0) * 1000, 1)
#
#             total_ms = round((time.perf_counter() - t_all0) * 1000, 1)
#             print(
#                 f"[LATENCY] STT={stt_ms} | NLP={nlp_ms} | "
#                 f"MAP={map_ms} | VIDEO={video_ms} | TOTAL={total_ms} ms"
#             )
#
#             payload = {
#                 "timestamp": ts,
#                 "snapshot_index": snap + 1,
#                 "raw": {
#                     "stt_text": stt,
#                     "snapshot_mode": "delta",
#                     "tail_seconds": None,
#                 },
#                 "timing": {
#                     "stt_ms": stt_ms,
#                     "nlp_ms": nlp_ms,
#                     "mapping_ms": map_ms,
#                     "video_ms": video_ms,
#                     "total_ms": total_ms,
#                 },
#                 "gemini": {
#                     "gloss": gloss_list,
#                     "gloss_ids": gloss_ids,
#                 },
#             }
#
#             json_path = str(base) + ".json"
#             with open(json_path, "w", encoding="utf-8") as f:
#                 json.dump(payload, f, ensure_ascii=False, indent=2)
#
#             print(f"[JSON] {json_path}")
#
#             snap += 1
#
#         except KeyboardInterrupt:
#             print("\n[ì¢…ë£Œ] Ctrl+C ê°ì§€")
#             break
#
#
# # =========================================================
# # ì‹¤í–‰ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (í˜„ì¬ ë¯¸ì‚¬ìš©)
# # =========================================================
#
# if __name__ == "__main__":
#     main()


# =========================================================
# API snapshot ì €ì¥ê¸°
# =========================================================

API_SNAPSHOT_DIR = ROOT_DIR / "snapshots" / "api"
API_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)


def save_api_snapshot(data: dict):
    """
    REST API í˜¸ì¶œ ì‹œ STT/NLP/ë§¤í•‘/í•©ì„± ì •ë³´ë¥¼ snapshot JSONìœ¼ë¡œ ì €ì¥.
    """
    ts = now_ts()
    out_path = API_SNAPSHOT_DIR / f"snapshot_{ts}.json"

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"[API Snapshot saved] {out_path}")
    return str(out_path)
