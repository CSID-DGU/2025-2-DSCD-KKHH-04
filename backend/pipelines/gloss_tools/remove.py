# remove_duplicates.py

from pathlib import Path

# ğŸ”¹ ìˆ˜ì •í•˜ê³  ì‹¶ì€ txt íŒŒì¼ ê²½ë¡œ
FILE_PATH = Path(r"C:\Users\user\Desktop\2025-2-DSCD-KKHH-04-git\backend\pipelines\gloss_tools\gloss_tokens_merged.txt")

def dedupe_txt(path: Path):
    # íŒŒì¼ ì½ê¸°
    lines = path.read_text(encoding="utf-8").splitlines()

    # ì–‘ìª½ ê³µë°± ì œê±° + ë¹ˆ ì¤„ ì œì™¸
    cleaned = [line.strip() for line in lines if line.strip()]

    # ì¤‘ë³µ ì œê±°(set) + ì›ë˜ ìˆœì„œ ìœ ì§€
    seen = set()
    deduped = []
    for word in cleaned:
        if word not in seen:
            deduped.append(word)
            seen.add(word)

    # ê²°ê³¼ ë‹¤ì‹œ íŒŒì¼ì— ì €ì¥
    path.write_text("\n".join(deduped), encoding="utf-8")

    print(f"ì¤‘ë³µ ì œê±° ì™„ë£Œ! ì´ {len(lines)} â†’ {len(deduped)} ë‹¨ì–´ë¡œ ì •ë¦¬ë¨.")
    print(f"íŒŒì¼ ìœ„ì¹˜: {path}")

if __name__ == "__main__":
    dedupe_txt(FILE_PATH)
