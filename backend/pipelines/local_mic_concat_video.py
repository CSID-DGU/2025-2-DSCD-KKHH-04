# backend/pipelines/local_mic_concat_video.py
# -*- coding: utf-8 -*-
"""
ë¡œì»¬ ë§ˆì´í¬ â†’ STT â†’ gloss_id â†’ ì—¬ëŸ¬ ìˆ˜ì–´ mp4ë¥¼ í•˜ë‚˜ì˜ mp4ë¡œ concat.

ì‹¤í–‰:
    (.venv) python local_mic_concat_video.py
"""

import sounddevice as sd
import whisper
import wave
import threading
import time
import os
import shutil
import subprocess
from datetime import datetime
from pathlib import Path

from pipeline import (
    _norm,
    extract_glosses,
    to_gloss_ids,
    load_gloss_index,
    GLOSS_DICT_PATH,
    _paths_from_ids,
)

WHISPER_MODEL_NAME = "medium"
LANG = "ko"
DEVICE = "cpu"

CHUNK = 1024
frames = []
frames_lock = threading.Lock()
_last_frame_idx = 0

ROOT_DIR = Path(__file__).resolve().parent
LOG_DIR = ROOT_DIR / "local_snapshots_concat"
LOG_DIR.mkdir(exist_ok=True)

COMBINED_DIR = ROOT_DIR / "combined_sign_videos"
COMBINED_DIR.mkdir(exist_ok=True)


def now_ts():
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def audio_callback(indata, frames_cnt, time_info, status):
    if status:
        print("[Audio status]", status)
    with frames_lock:
        frames.append(bytes(indata))


def cut_delta_audio():
    global _last_frame_idx
    with frames_lock:
        cur = len(frames)
        if cur <= _last_frame_idx:
            return b""
        blob = b"".join(frames[_last_frame_idx:cur])
        _last_frame_idx = cur
        return blob


def concat_videos(paths, out_path: Path) -> bool:
    """ffmpeg concatìœ¼ë¡œ paths ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ mp4ë¡œ í•©ì„±."""
    if not paths:
        print("âš  í•©ì¹  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    ffmpeg = shutil.which("ffmpeg") or "ffmpeg"

    tmp_list = out_path.with_suffix(".txt")
    with open(tmp_list, "w", encoding="utf-8") as f:
        for p in paths:
            f.write(f"file '{p}'\n")

    cmd = [
        ffmpeg, "-y",
        "-f", "concat", "-safe", "0",
        "-i", str(tmp_list),
        "-vf", "format=yuv420p",
        "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
        "-c:a", "aac", "-b:a", "128k",
        str(out_path),
    ]
    r = subprocess.run(cmd)
    try:
        os.remove(tmp_list)
    except OSError:
        pass
    return r.returncode == 0


def main():
    print("\n[1] gloss index ë¡œë“œâ€¦")
    index = load_gloss_index(GLOSS_DICT_PATH)

    print("\n[2] Whisper ëª¨ë¸ ë¡œë“œâ€¦")
    model = whisper.load_model(WHISPER_MODEL_NAME, device=DEVICE)

    print("\n[3] ì˜¤ë””ì˜¤ ì¥ì¹˜ ëª©ë¡:")
    for i, dev in enumerate(sd.query_devices()):
        print(f"  #{i}: {dev['name']} (inputs={dev['max_input_channels']})")

    dev = sd.query_devices(kind="input")
    samplerate = int(dev["default_samplerate"])
    print(f"\nğŸ™ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜: {dev['name']} @ {samplerate} Hz\n")

    stream = sd.RawInputStream(
        samplerate=samplerate,
        channels=1,
        dtype="int16",
        blocksize=CHUNK,
        callback=audio_callback,
    )
    stream.start()

    print("==============================================")
    print("Enter â†’ STT + gloss_id â†’ mp4 concat íŒŒì¼ ìƒì„±")
    print("Ctrl + C â†’ ì¢…ë£Œ")
    print("==============================================")

    snap_idx = 0

    while True:
        try:
            input("\n[Enter] STT + mp4 concat â–¶ ")
            blob = cut_delta_audio()
            if not blob:
                print("ìƒˆ ì˜¤ë””ì˜¤ ì—†ìŒ.")
                continue

            ts = now_ts()
            base = LOG_DIR / f"concat_{ts}_{snap_idx:02d}"

            wav_path = str(base) + ".wav"
            with wave.open(wav_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(samplerate)
                wf.writeframes(blob)
            print(f"[WAV] {wav_path}")

            t0 = time.perf_counter()
            res = model.transcribe(
                wav_path,
                language=LANG,
                task="transcribe",
                temperature=0.0,
                beam_size=5,
                best_of=5,
            )
            latency = round((time.perf_counter() - t0) * 1000, 1)
            text = _norm(res.get("text") or "")
            print(f"[STT] {text}  (lat={latency}ms)")

            gloss = extract_glosses(text, None)
            gids = to_gloss_ids(gloss, index)
            print("[GLOSS]", gloss)
            print("[GLOSS_ID]", gids)

            paths = _paths_from_ids(gids)
            print("[VIDEO PATHS]", paths)

            out_path = COMBINED_DIR / f"sign_seq_{ts}.mp4"
            if concat_videos(paths, out_path):
                print(f"[DONE] í•©ì„± ì˜ìƒ: {out_path}")
            else:
                print("âŒ ffmpeg concat ì‹¤íŒ¨")

            snap_idx += 1

        except KeyboardInterrupt:
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤â€¦")
            break

    stream.stop()
    stream.close()


if __name__ == "__main__":
    main()
