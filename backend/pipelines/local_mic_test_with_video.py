# backend/pipelines/local_mic_test_with_video.py
# -*- coding: utf-8 -*-
"""
ë¡œì»¬ ë§ˆì´í¬ â†’ Whisper STT â†’ ê¸€ë¡œìŠ¤ ì¶”ì¶œ â†’ gloss_id ë§¤í•‘ â†’ ìˆ˜ì–´ ì˜ìƒ ì¬ìƒ í…ŒìŠ¤íŠ¸

ì‹¤í–‰:
    (.venv) python local_mic_test_with_video.py
"""

import sounddevice as sd
import whisper
import wave
import threading
import time
import os
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
import sys

# ë„ˆì˜ ì„œë²„ìš© pipeline.py í•¨ìˆ˜ë“¤ import
from pipeline import (
    _norm,
    extract_glosses,
    to_gloss_ids,
    load_gloss_index,
    GLOSS_DICT_PATH,
    _paths_from_ids,   # MEDIA_ROOT/sign_videos ê¸°ì¤€ gloss_id â†’ mp4 ê²½ë¡œ
)

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
WHISPER_MODEL_NAME = "medium"   # small â†’ medium ì´ìƒ ì¶”ì²œ
LANG = "ko"
DEVICE = "cpu"                  # GPU ìˆìœ¼ë©´ "cuda"

CHUNK = 1024
frames = []
frames_lock = threading.Lock()
_last_frame_idx = 0

ROOT_DIR = Path(__file__).resolve().parent
LOG_DIR = ROOT_DIR / "local_snapshots_with_video"
LOG_DIR.mkdir(exist_ok=True)


def now_ts():
    return datetime.now().strftime("%Y%m%d_%H%M%S")


# ---------------- ì˜¤ë””ì˜¤ ì½œë°± ----------------
def audio_callback(indata, frames_cnt, time_info, status):
    if status:
        print("[Audio status]", status)
    with frames_lock:
        frames.append(bytes(indata))


def cut_delta_audio():
    """ì§ì „ ì´í›„ ëˆ„ì ë¶„ë§Œ blobìœ¼ë¡œ ì˜ë¼ì˜¤ê¸°."""
    global _last_frame_idx
    with frames_lock:
        cur = len(frames)
        if cur <= _last_frame_idx:
            return b""
        blob = b"".join(frames[_last_frame_idx:cur])
        _last_frame_idx = cur
        return blob


# ---------------- ì˜ìƒ ì¬ìƒ ìœ í‹¸ ----------------
def play_sequence(paths):
    """
    ffplay ë˜ëŠ” ffmpegë¥¼ ì‚¬ìš©í•´ mp4 ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ì¬ìƒ.
    - ffplay ìˆìœ¼ë©´ concat demuxerë¡œ ë°”ë¡œ ì¬ìƒ
    - ì—†ìœ¼ë©´ ì„ì‹œ concat mp4 ë§Œë“¤ì–´ì„œ OS ê¸°ë³¸ í”Œë ˆì´ì–´ë¡œ ì˜¤í”ˆ
    """
    if not paths:
        print("âš  ì¬ìƒí•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    ffmpeg = shutil.which("ffmpeg") or "ffmpeg"
    ffplay = shutil.which("ffplay")

    # 1) ffplay ìˆìœ¼ë©´ concatìœ¼ë¡œ ë°”ë¡œ ì¬ìƒ
    if ffplay:
        import tempfile
        with tempfile.NamedTemporaryFile("w", suffix=".txt", delete=False) as f:
            lst_path = f.name
            for p in paths:
                f.write(f"file '{p}'\n")
        try:
            cmd = [
                ffplay,
                "-autoexit",
                "-hide_banner",
                "-loglevel", "error",
                "-f", "concat",
                "-safe", "0",
                "-i", lst_path,
            ]
            subprocess.run(cmd, check=True)
            return True
        finally:
            try:
                os.remove(lst_path)
            except OSError:
                pass

    # 2) ffplay ì—†ìœ¼ë©´ ffmpegë¡œ ì„ì‹œ mp4 í•©ì„± í›„ OSë¡œ ì—´ê¸°
    import tempfile
    with tempfile.TemporaryDirectory() as td:
        lst = Path(td) / "list.txt"
        out = Path(td) / f"concat_{now_ts()}.mp4"

        with open(lst, "w", encoding="utf-8") as f:
            for p in paths:
                f.write(f"file '{p}'\n")

        cmd = [
            ffmpeg, "-y",
            "-f", "concat", "-safe", "0",
            "-i", str(lst),
            "-vf", "format=yuv420p",
            "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
            "-c:a", "aac", "-b:a", "128k",
            str(out),
        ]
        subprocess.run(cmd, check=True)

        if os.name == "nt":      # Windows
            os.startfile(str(out))
        elif sys.platform == "darwin":
            subprocess.Popen(["open", str(out)])
        else:
            subprocess.Popen(["xdg-open", str(out)])
        return True


# ---------------- ë©”ì¸ ----------------
def main():
    print("\n[1] ê¸€ë¡œìŠ¤ ì‚¬ì „ ë¡œë“œâ€¦")
    index = load_gloss_index(GLOSS_DICT_PATH)
    print(" â†’ gloss index ë¡œë“œ ì™„ë£Œ.")

    print("\n[2] Whisper ëª¨ë¸ ë¡œë“œâ€¦")
    model = whisper.load_model(WHISPER_MODEL_NAME, device=DEVICE)
    print(f" â†’ Whisper '{WHISPER_MODEL_NAME}' on {DEVICE}")

    # ì˜¤ë””ì˜¤ ë””ë°”ì´ìŠ¤ ì •ë³´
    print("\n[3] ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ëª©ë¡:")
    for i, dev in enumerate(sd.query_devices()):
        print(f"  #{i}: {dev['name']} (inputs={dev['max_input_channels']})")

    dev = sd.query_devices(kind="input")
    samplerate = int(dev["default_samplerate"])
    print(f"\nğŸ™ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜: {dev['name']} @ {samplerate} Hz\n")

    # ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    stream = sd.RawInputStream(
        samplerate=samplerate,
        channels=1,
        dtype="int16",
        blocksize=CHUNK,
        callback=audio_callback,
    )
    stream.start()

    print("==============================================")
    print("ë¡œì»¬ ë§ˆì´í¬ ë…¹ìŒ ì‹œì‘.")
    print("Enter â†’ ì§ì „ êµ¬ê°„ STT + ìˆ˜ì–´ ì˜ìƒ ì¬ìƒ")
    print("Ctrl + C â†’ ì¢…ë£Œ")
    print("==============================================")

    snap_idx = 0

    while True:
        try:
            input("\n[Enter] STT + ìˆ˜ì–´ ì¬ìƒ â–¶ ")
            blob = cut_delta_audio()
            if not blob:
                print("ìƒˆ ì˜¤ë””ì˜¤ ì—†ìŒ.")
                continue

            ts = now_ts()
            base = LOG_DIR / f"local_{ts}_{snap_idx:02d}"

            wav_path = str(base) + ".wav"
            with wave.open(wav_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(samplerate)
                wf.writeframes(blob)
            print(f"[WAV] {wav_path}")

            t0 = time.perf_counter()
            res = model.transcribe(
                wav_path,
                language=LANG,
                task="transcribe",
                temperature=0.0,
                beam_size=5,
                best_of=5,
            )
            latency = round((time.perf_counter() - t0) * 1000, 1)
            text = _norm(res.get("text") or "")
            print(f"[STT] {text}  (lat={latency}ms)")

            gloss = extract_glosses(text, None)
            gids = to_gloss_ids(gloss, index)
            print("[GLOSS]", gloss)
            print("[GLOSS_ID]", gids)

            # gloss_id â†’ mp4 ê²½ë¡œë“¤ â†’ ì¬ìƒ
            paths = _paths_from_ids(gids)
            print("[VIDEO PATHS]", paths)
            play_sequence(paths)

            snap_idx += 1

        except KeyboardInterrupt:
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤â€¦")
            break

    stream.stop()
    stream.close()


if __name__ == "__main__":
    main()
