# -*- coding: utf-8 -*-
"""
service.py
Django API(/speech_to_sign)ì—ì„œ í˜¸ì¶œë˜ëŠ” íŒŒì´í”„ë¼ì¸ ë˜í¼

ê¸°ëŠ¥:
- ì—…ë¡œë“œëœ audio íŒŒì¼ â†’ wav ë³€í™˜
- STT â†’ clean â†’ gloss ì¶”ì¶œ
- gloss â†’ gloss_id ë§¤í•‘
- gloss_id â†’ mp4 ì˜ìƒ ë¦¬ìŠ¤íŠ¸
- ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ concat
- latency ì¸¡ì •
- ìŠ¤ëƒ…ìƒ·(snapshot) ì €ì¥ (backend/snapshots/api)
- í”„ë¡ íŠ¸ê°€ ì½ëŠ” ìµœì¢… ê²°ê³¼ JSON êµ¬ì„±
"""

import os
import subprocess
import tempfile
from pathlib import Path
import json
import time
import csv
import ast
import contextlib
import wave

from django.conf import settings

# ============================== #
# pipeline.py ë‚´ë¶€ ê¸°ëŠ¥ import
# ============================== #
from .pipeline import (
    stt_from_file,
    extract_glosses,      # (ë¹„ìƒìš©; ê¸°ë³¸ì€ nlp_with_gemini ì‚¬ìš©)
    to_gloss_ids,
    load_gloss_index,
    _paths_from_ids,
    build_gemini,
    MEDIA_ROOT,
    now_ts,
    OUT_DIR,
    _norm,
    GEMINI_MODEL,         
)
# ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ gloss ì¶”ì¶œìš© (Gemini ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©)
from .pipeline import _local_gloss_rules

# ğŸ”¹ ì—¬ê¸° ì¶”ê°€
from .pipeline import generate_image_video
import re

# ==============================
# API Snapshot ë””ë ‰í† ë¦¬
# ==============================
BASE_DIR = Path(__file__).resolve().parent.parent   # backend/
API_SNAPSHOT_DIR = BASE_DIR / "snapshots" / "api"
API_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)


def nlp_with_gemini(text, model):
    """
    Geminiê°€ {"clean": "...", "gloss": [...]} í˜•íƒœë¡œ ì¤„ ë•Œ
    clean & gloss ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    ì˜¤ë¥˜ ì‹œ fallback = (ì›ë¬¸ ì •ê·œí™”, ë¡œì»¬ gloss)

    ë°˜í™˜:
      clean_text: êµì •ëœ ë¬¸ì¥ (ë˜ëŠ” STT ì •ê·œí™”)
      gloss_list: ì˜ë¯¸ ë‹¨ìœ„ í† í° ë¦¬ìŠ¤íŠ¸
    """
    # 1) Gemini ëª¨ë¸ì´ ì „í˜€ ì¤€ë¹„ ì•ˆ ëœ ê²½ìš° â†’ STT ì •ê·œí™” + ë¡œì»¬ ê·œì¹™ gloss
    if not model:
        clean = _norm(text)
        gloss = _local_gloss_rules(clean)
        return clean, gloss

    try:
        # 2) Gemini í˜¸ì¶œ
        #    system_instruction(build_gemini)ì—ì„œ ì´ë¯¸
        #    {"clean":"â€¦","gloss":["â€¦"]} í˜•ì‹ìœ¼ë¡œ JSONë§Œ ë°˜í™˜í•˜ë„ë¡ ì§€ì‹œí•¨.
        prompt = f"""
ì—­í• : í•œêµ­ì–´ ì „ì‚¬ êµì • + ìˆ˜ì–´ ê¸€ë¡œìŠ¤ ì¶”ì¶œê¸°.
ì•„ë˜ í•œêµ­ì–´ ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ JSON í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ì„¸ìš”.

í˜•ì‹:
{{
  "clean": "<êµì •ëœ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥>",
  "gloss": ["ì˜ë¯¸ë‹¨ì–´1","ì˜ë¯¸ë‹¨ì–´2", ...]
}}

ê·œì¹™:
- "clean": ì›ë¬¸ì˜ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜ ë¶ˆí•„ìš”í•œ ë°˜ë³µ, ë§íˆ¬, ì¡°ì‚¬ ë“±ì„ ì •ë¦¬í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥
- "gloss": ì¡°ì‚¬ë¥¼ ì œê±°í•œ í•µì‹¬ ì˜ë¯¸ ë‹¨ì–´ë“¤ë§Œ, ì¤‘ë³µ ì—†ì´ 1~10ê°œ ì •ë„
- ì¶œë ¥ì€ ìœ„ JSON í•˜ë‚˜ë§Œ, ì¶”ê°€ ì„¤ëª…/ë¬¸ì¥ì€ ë„£ì§€ ë§ ê²ƒ.

ì…ë ¥: "{text}"
"""
        resp = model.generate_content(prompt)

        # build_geminiì—ì„œ response_mime_type="application/json"ì„ ì¤¬ê¸° ë•Œë¬¸ì—
        # resp.textëŠ” JSON ë¬¸ìì—´ì´ì–´ì•¼ í•¨.
        raw = resp.text
        data = json.loads(raw)

        # 3) clean / gloss íŒŒì‹±
        clean = _norm(data.get("clean", text))

        gloss_raw = data.get("gloss", [])
        gloss = []
        for x in gloss_raw:
            s = _norm(str(x))
            if s:
                gloss.append(s)

        # í˜¹ì‹œ glossê°€ ë¹„ì–´ë²„ë ¸ë‹¤ë©´ ìµœì†Œí•œ ë¡œì»¬ ê·œì¹™ì´ë¼ë„ ì‚¬ìš©
        if not gloss:
            gloss = _local_gloss_rules(clean)

        return clean, gloss

    except Exception as e:
        # 4) ì–´ë–¤ ì´ìœ ë¡œë“  Gemini íŒŒì‹± ì‹¤íŒ¨ ì‹œ â†’ ì•ˆì „í•œ fallback
        print(f"[Gemini NLP ERROR] {e}")
        clean = _norm(text)
        gloss = _local_gloss_rules(clean)
        return clean, gloss


def save_api_snapshot(payload: dict) -> str:
    """REST API í˜¸ì¶œ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
    ts = now_ts()
    out_path = API_SNAPSHOT_DIR / f"snapshot_{ts}.json"

    try:
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        print(f"[API Snapshot saved] {out_path}")
    except Exception as e:
        print(f"[API Snapshot ERROR] {e}")

    return str(out_path)


# ==============================
# ë¬¸ì¥ ë‹¨ìœ„ ìˆ˜ì–´ ì˜ìƒ ì €ì¥ í´ë”
# ==============================
SENTENCE_DIR = MEDIA_ROOT / "sign_sentences"
SENTENCE_DIR.mkdir(parents=True, exist_ok=True)

# ==============================
# ê¸€ë¡œìŠ¤ ì‚¬ì „ ì „ì—­ ë¡œë”©
# ==============================
GLOSS_INDEX = load_gloss_index()

# ---------- gloss_id -> korean_meanings ë§¤í•‘ ë¡œë” ----------
GLOSS_CSV_PATH = BASE_DIR / "data" / "gloss_dictionary_MOCK_1.csv"


def load_gloss_meanings():
    """
    gloss_dictionary_MOCK_1.csvì—ì„œ
    gloss_id -> [korean_meanings ë¦¬ìŠ¤íŠ¸] ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    """
    mapping = {}
    with open(GLOSS_CSV_PATH, "r", encoding="utf-8-sig") as f:
        rdr = csv.DictReader(f)
        for row in rdr:
            gid = (row.get("gloss_id") or "").strip()
            cell = (row.get("korean_meanings") or "").strip()
            if not gid or not cell:
                continue

            # '["ì˜ˆê¸ˆ","ì˜ˆê¸ˆìƒí’ˆ"]' ê°™ì€ ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±
            try:
                obj = ast.literal_eval(cell)
                if isinstance(obj, (list, tuple)):
                    terms = [str(x) for x in obj]
                else:
                    terms = [str(obj)]
            except Exception:
                terms = [cell]

            mapping[gid] = terms
    return mapping


GLOSS_MEANINGS = load_gloss_meanings()
# -----------------------------------------------------------


def concat_videos_ffmpeg(video_paths):
    """ì—¬ëŸ¬ ê°œ ìˆ˜ì–´ mp4ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ ìƒì„±"""
    if not video_paths:
        return None, None

    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".txt", delete=False, encoding="utf-8"
    ) as f:
        for p in video_paths:
            f.write(f"file '{p}'\n")
        list_path = f.name

    out_name = f"sent_{now_ts()}.mp4"
    out_path = SENTENCE_DIR / out_name

    cmd = [
        "ffmpeg", "-y",
        "-f", "concat",
        "-safe", "0",
        "-i", list_path,
        "-c", "copy",
        str(out_path),
    ]

    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    finally:
        try:
            os.remove(list_path)
        except OSError:
            pass

    return out_path, f"/media/sign_sentences/{out_name}"


def convert_to_wav_if_needed(src_path: Path) -> Path:
    """webm/mp3 ë“± â†’ wav(16kHz, mono) ë³€í™˜"""
    if src_path.suffix.lower() == ".wav":
        return src_path

    dst_path = src_path.with_suffix(".wav")

    cmd = [
        "ffmpeg", "-y",
        "-i", str(src_path),
        "-ar", "16000",
        "-ac", "1",
        "-c:a", "pcm_s16le",
        str(dst_path),
    ]

    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return dst_path


def get_audio_duration(path: Path) -> float:
    """
    wav íŒŒì¼ ê¸¸ì´(ì´ˆ) êµ¬í•˜ê¸°.
    ì‹¤íŒ¨í•˜ë©´ 0.0 ë°˜í™˜.
    """
    try:
        with contextlib.closing(wave.open(str(path), "rb")) as wf:
            frames = wf.getnframes()
            rate = wf.getframerate()
            if rate == 0:
                return 0.0
            return frames / float(rate)
    except Exception as e:
        print(f"[Perf] get_audio_duration error: {e}")
        return 0.0


# ==============================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (APIì—ì„œ í˜¸ì¶œ)
# ==============================
def process_audio_file(django_file, mode=None, session_id=None):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ì—¬
    STT â†’ NLP â†’ gloss_id â†’ ì˜ìƒ í•©ì„± â†’ latency â†’ snapshot ì €ì¥ â†’ ìµœì¢… ì‘ë‹µ

    mode: "ì§ˆë¬¸" / "ì‘ë‹µ" ë“± í”„ë¡ íŠ¸ì—ì„œ ë„˜ê²¨ì£¼ëŠ” ë°œí™” íƒ€ì… (ì„ íƒ)
    session_id: ì´ë²ˆ ìƒë‹´ ì„¸ì…˜ ì‹ë³„ì (ì„ íƒ)
    """

    # ----------------------------------------
    # 1) ì—…ë¡œë“œ íŒŒì¼ì„ temp í´ë”ì— ì €ì¥
    # ----------------------------------------
    temp_dir = Path(settings.MEDIA_ROOT) / "temp"
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / django_file.name

    with open(temp_path, "wb") as f:
        for chunk in django_file.chunks():
            f.write(chunk)

    # webm â†’ wav ë³€í™˜
    wav_path = convert_to_wav_if_needed(temp_path)

    # wav ê¸¸ì´(ì´ˆ) ì¸¡ì • (STT ì„±ëŠ¥ ë¹„êµìš©)
    audio_sec = get_audio_duration(wav_path)

    latency = {}   # latency ê¸°ë¡ìš©

    # ----------------------------------------
    # 2) STT
    # ----------------------------------------
    t0 = time.perf_counter()
    text = stt_from_file(str(wav_path))   # Whisper STT ê²°ê³¼ (ì›ë¬¸)
    t1 = time.perf_counter()
    latency["stt"] = round((t1 - t0) * 1000, 1)

    # STT ì„±ëŠ¥ ë¡œê·¸
    stt_ms = latency["stt"]
    ratio = stt_ms / (audio_sec * 1000 + 1e-6) if audio_sec else 0.0
    print(f"[Perf] audio_sec={audio_sec:.2f}, stt_ms={stt_ms:.1f}, ratio={ratio:.2f}")
    print(f"[DEBUG] STT raw text: {repr(text)}")

    # ----------------------------------------
    # 3) NLP ë‹¨ê³„: clean + gloss ì¶”ì¶œ
    #    (Gemini ì‚¬ìš© â†’ clean_text / gloss ëª¨ë‘ ì—¬ê¸°ì„œ ê²°ì •)
    # ----------------------------------------
    model = GEMINI_MODEL   # ğŸ”¹ ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ build ëœ ì „ì—­ ëª¨ë¸

    t2 = time.perf_counter()
    clean_text, gloss_list = nlp_with_gemini(text, model)
    t3 = time.perf_counter()
    latency["nlp"] = round((t3 - t2) * 1000, 1)

    # ----------------------------------------
        # ----------------------------------------
    # 4) gloss â†’ gloss_id ë§¤í•‘
    # ----------------------------------------
    t4 = time.perf_counter()
    gloss_ids = to_gloss_ids(gloss_list, GLOSS_INDEX)
    video_paths = _paths_from_ids(gloss_ids)
    t5 = time.perf_counter()
    latency["mapping"] = round((t5 - t4) * 1000, 1)

    # ğŸ”¹ 4-1) ìˆ«ì/ì´ë¯¸ì§€ í† í°ì— ëŒ€í•œ fallback: ì´ë¯¸ì§€ ê¸°ë°˜ ë™ì˜ìƒ ìƒì„±
    #  - ì˜ˆ: "18ì„¸", "3ë…„", "2íšŒ", "5%" ê°™ì€ í† í°
    extra_video_paths = []
    num_pattern = re.compile(r"^\d+[ê°€-í£%ë…„ì›”ì„¸ì›ë§Œì›ì–µê°œì›”íšŒ]*$")

    for tok in gloss_list or []:
        t = _norm(str(tok))
        if not t:
            continue

        # ìˆ«ì ê¸°ë°˜ í† í°ì´ë©´ ì´ë¯¸ì§€ ë™ì˜ìƒ ìƒì„±
        if num_pattern.match(t):
            try:
                img_mp4 = generate_image_video(t, duration=1.5)
                extra_video_paths.append(img_mp4)
                print(f"[Fallback ImageVideo] token={t} -> {img_mp4}")
            except Exception as e:
                print(f"[Fallback ImageVideo ERROR] token={t}: {e}")

    # ìµœì¢… í•©ì„±ì— ì“¸ ê²½ë¡œë“¤ (ê¸°ì¡´ ìˆ˜ì–´ ì˜ìƒ + ìˆ«ì ì´ë¯¸ì§€ ì˜ìƒ)
    video_paths_for_concat = video_paths + extra_video_paths

    # gloss_id â†’ í•œê¸€ meaning ëŒ€í‘œ ë ˆì´ë¸”
    gloss_labels = []
    for gid in gloss_ids:
        terms = GLOSS_MEANINGS.get(gid) or []
        if terms:
            gloss_labels.append(terms[0])  # ëŒ€í‘œ ì˜ë¯¸ 1ê°œ
        else:
            gloss_labels.append(gid)

    # ----------------------------------------
    # 5) ì˜ìƒ í•©ì„±
    # ----------------------------------------
    t6 = time.perf_counter()
    sent_abs, sent_url = concat_videos_ffmpeg(video_paths_for_concat)
    t7 = time.perf_counter()
    latency["synth"] = round((t7 - t6) * 1000, 1)

        # ê°œë³„ ì˜ìƒ URL ë¦¬ìŠ¤íŠ¸(sign_video_list) êµ¬ì„±
    # - video_paths_for_concat ì•ˆì—ëŠ” ê¸°ì¡´ ìˆ˜ì–´ mp4 + ìˆ«ì ì´ë¯¸ì§€ mp4ê°€ ëª¨ë‘ ë“¤ì–´ ìˆìŒ
    sign_video_list = []
    for p in video_paths_for_concat:
        p = Path(p)
        try:
            # MEDIA_ROOT ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ ë°”ê¾¼ ë’¤ MEDIA_URLì„ ë¶™ì—¬ì„œ URL ë§Œë“¤ê¸°
            rel = p.relative_to(MEDIA_ROOT)
            url = settings.MEDIA_URL.rstrip("/") + "/" + str(rel).replace("\\", "/")
            sign_video_list.append(url)
        except ValueError:
            # MEDIA_ROOT ë°–ì´ë©´ ì¼ë‹¨ íŒŒì¼ëª…ë§Œ ë„£ì–´ë‘  (ìµœì†Œ NameErrorëŠ” ì•ˆ ë‚˜ê²Œ)
            sign_video_list.append(str(p))
    # ----------------------------------------
    # 6) ë””ë²„ê·¸ ë¡œê·¸ (ì§€ê¸ˆ ì–´ë””ê¹Œì§€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸ìš©)
    # ----------------------------------------
    print("\n========== [DEBUG process_audio_file] ==========")
    print(f"text (STT ì›ë¬¸): {repr(text)}")
    print(f"clean_text: {repr(clean_text)}")
    print(f"gloss_list: {gloss_list}")
    print(f"gloss_ids: {gloss_ids}")
    print(f"gloss_labels: {gloss_labels}")
    print(f"video_paths: {video_paths}")
    print(f"sentence_video_url: {sent_url}")
    print(f"latency_ms: {latency}")
    print(f"video_paths_for_concat: {video_paths_for_concat}")
    print(f"sign_video_list: {sign_video_list}")
    print(f"sentence_video_url: {sent_url}")

    print("===============================================\n")

    # ----------------------------------------
    # 7) API ìŠ¤ëƒ…ìƒ· ì €ì¥ (latency í¬í•¨)
    # ----------------------------------------
        # ----------------------------------------
    # 7) API ìŠ¤ëƒ…ìƒ· ì €ì¥ (latency í¬í•¨)
        # ----------------------------------------
    # 7) latency ë³´ì •: sec ë‹¨ìœ„ + totalê¹Œì§€ ê³„ì‚°
    # ----------------------------------------
    # ms ë‹¨ìœ„ì—ì„œ êº¼ë‚´ê¸° (ì—†ëŠ” í‚¤ëŠ” 0ìœ¼ë¡œ)
    stt_ms     = float(latency.get("stt", 0.0))
    nlp_ms     = float(latency.get("nlp", 0.0))
    mapping_ms = float(latency.get("mapping", 0.0))
    synth_ms   = float(latency.get("synth", 0.0))

    total_ms = stt_ms + nlp_ms + mapping_ms + synth_ms

    # í•„ìš”í•˜ë©´ sec ë‹¨ìœ„ë„ ê°™ì´ ë§Œë“¤ì–´ì£¼ê¸°
    latency_sec = {
        "stt_sec":     round(stt_ms / 1000.0, 2),
        "nlp_sec":     round(nlp_ms / 1000.0, 2),
        "mapping_sec": round(mapping_ms / 1000.0, 2),
        "synth_sec":   round(synth_ms / 1000.0, 2),
        "total_sec":   round(total_ms / 1000.0, 2),
    }

    # ë””ë²„ê·¸ ì¶œë ¥ (ê·¸ ë¬¸ì¥ 1: ~~ s / ì´í•©: ~~ s í˜•íƒœ)
    print(
        f"[Perf Sentence] STT: {latency_sec['stt_sec']:.2f} s / "
        f"NLP: {latency_sec['nlp_sec']:.2f} s / "
        f"ë§¤í•‘: {latency_sec['mapping_sec']:.2f} s / "
        f"í•©ì„±: {latency_sec['synth_sec']:.2f} s"
    )
    print(f"[Perf Sentence] ì´í•©: {latency_sec['total_sec']:.2f} s")


    # ----------------------------------------
    current_ts = now_ts()  # ğŸ”¹ í•œ ë²ˆë§Œ í˜¸ì¶œí•´ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©

    result = {
        # ğŸ”¹ ëŒ€ì‹œë³´ë“œ/í”„ë¡ íŠ¸ ê³µí†µìœ¼ë¡œ ì“¸ ì‹œê°„ í•„ë“œ
        "ts": current_ts,          # PerformanceDashboardì—ì„œ ìš°ì„  ì‚¬ìš©
        "timestamp": current_ts,   # ê¸°ì¡´ í•„ë“œë„ ìœ ì§€

        "session_id": session_id,    # ì´ë²ˆ ìƒë‹´ ì„¸ì…˜ ID (ì—†ìœ¼ë©´ None)
        "mode": mode,                # "ì§ˆë¬¸"/"ì‘ë‹µ" ë“± ë°œí™” íƒ€ì… (ì—†ìœ¼ë©´ None)
        "audio_sec": audio_sec,      # ì´ë²ˆ ë°œí™” ê¸¸ì´(ì´ˆ)
        "text": text,                # STT ì›ë¬¸
        "clean_text": clean_text,    # Gemini NLP ê²°ê³¼ (or fallback)
        "latency_ms": latency,
        "latency_sec": latency_sec,
        "gloss": gloss_list,
        "gloss_ids": gloss_ids,
        "sentence_video_url": sent_url,   # ëŒ€í‘œ ë¬¸ì¥ ì˜ìƒ
        "sign_video_list": sign_video_list,    # ê°œë³„ ì˜ìƒ ë¦¬ìŠ¤íŠ¸
        "gloss_labels": gloss_labels,     # gloss_id â†’ ëŒ€í‘œ í•œê¸€ ì˜ë¯¸
    }


    save_api_snapshot(result)

    # ----------------------------------------
    # 8) í”„ë¡ íŠ¸ë¡œ ë°˜í™˜
    # ----------------------------------------
    return result
