# -*- coding: utf-8 -*-
"""
service.py
Django API(/speech_to_sign)ì—ì„œ í˜¸ì¶œë˜ëŠ” íŒŒì´í”„ë¼ì¸ ë˜í¼

ê¸°ëŠ¥:
- ì—…ë¡œë“œëœ audio íŒŒì¼ â†’ wav ë³€í™˜
- STT â†’ Gemini(NLP) â†’ cleaned + tokens(gloss/image/pause)
- tokens â†’ gloss_list / gloss_ids / ìˆ˜ì–´ mp4 ì˜ìƒ ë¦¬ìŠ¤íŠ¸
- ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ concat
- latency ì¸¡ì •
- ìŠ¤ëƒ…ìƒ·(snapshot) ì €ì¥ (backend/snapshots/api)
- í”„ë¡ íŠ¸ê°€ ì½ëŠ” ìµœì¢… ê²°ê³¼ JSON êµ¬ì„±
"""

import os
import subprocess
import tempfile
from pathlib import Path
import json
import time
import csv
import ast
import contextlib
import wave
import re

from django.conf import settings
from django.core.cache import cache  # ğŸ”¹ ì¶”ê°€

# ============================== #
# pipeline.py ë‚´ë¶€ ê¸°ëŠ¥ import
# ============================== #
from .pipeline import (
    stt_from_file,
    extract_glosses,      # (ë¹„ìƒìš©; ê¸°ë³¸ì€ nlp_with_gemini ì‚¬ìš©)
    to_gloss_ids,
    load_gloss_index,
    _paths_from_ids,
    build_gemini,
    MEDIA_ROOT,
    now_ts,
    OUT_DIR,
    _norm,
    GEMINI_MODEL,
    _local_gloss_rules,
    apply_text_normalization,
    WHISPER_LOAD_MS,
    log_gloss_mapping,    # ğŸ”¹ gloss ë§¤í•‘ ë¡œê·¸
    build_video_sequence_from_tokens,  # ğŸ”¹ tokens â†’ ì˜ìƒ ì‹œí€€ìŠ¤
)

# ==============================
# API Snapshot ë””ë ‰í† ë¦¬
# ==============================
BASE_DIR = Path(__file__).resolve().parent.parent   # backend/
API_SNAPSHOT_DIR = BASE_DIR / "snapshots" / "api"
API_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)


def nlp_with_gemini(text, model):
    """
    Geminiê°€ {"cleaned": "...", "tokens": [...]} í˜•ì‹ìœ¼ë¡œ ì¤„ ë•Œ
    cleaned & tokens ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    ì˜¤ë¥˜ ì‹œ fallback = (STT ì •ê·œí™”, ë¡œì»¬ gloss)

    ë°˜í™˜:
      cleaned: ì •ê·œí™”ëœ í•œêµ­ì–´ ë¬¸ì¥ (ìë§‰ìš©)
      gloss : tokens ì¤‘ type=="gloss"ë§Œ ë½‘ì€ ë¦¬ìŠ¤íŠ¸
      tokens: [{text, type}] ë¦¬ìŠ¤íŠ¸ (gloss / image / pause)
    """
    clean = _norm(text)

    # 1) Gemini ëª¨ë¸ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ â†’ ì •ê·œí™” + ë¡œì»¬ ê·œì¹™
    if not model:
        tokens = []
        gloss = _local_gloss_rules(clean)
        return clean, gloss, tokens

    try:
        # build_geminiì—ì„œ system_instruction + response_mime_type=application/json ì„¸íŒ… ì™„ë£Œ
        parts = [{"role": "user", "parts": [clean]}]
        resp = model.generate_content(parts)

        raw = resp.text if getattr(resp, "text", None) else ""
        raw = (raw or "").strip()

        # ```json ... ``` ë˜í•‘ ì œê±°
        if raw.startswith("```"):
            raw = raw.strip("`")
            if raw.lower().startswith("json"):
                raw = raw[4:].lstrip()

        # ë³¸ë¬¸ì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1 and end > start:
            raw_json = raw[start : end + 1]
        else:
            raw_json = raw

        obj = json.loads(raw_json)

        cleaned = _norm(obj.get("cleaned") or clean)
        tokens = obj.get("tokens") or []

        # gloss ë¦¬ìŠ¤íŠ¸ëŠ” tokensì—ì„œ type=="gloss"ë§Œ ëª¨ì•„ì„œ ë§Œë“¤ê¸°
        gloss = [
            (t.get("text") or "").strip()
            for t in tokens
            if isinstance(t, dict)
            and t.get("type", "gloss") == "gloss"
            and (t.get("text") or "").strip()
        ]

        if not gloss:
            gloss = _local_gloss_rules(cleaned)

        return cleaned, gloss, tokens

    except Exception as e:
        print(f"[Gemini NLP ERROR] {e}")
        cleaned = _norm(text)
        gloss = _local_gloss_rules(cleaned)
        return cleaned, gloss, []


def save_api_snapshot(payload: dict) -> str:
    """REST API í˜¸ì¶œ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
    ts = now_ts()
    out_path = API_SNAPSHOT_DIR / f"snapshot_{ts}.json"

    try:
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        print(f"[API Snapshot saved] {out_path}")
    except Exception as e:
        print(f"[API Snapshot ERROR] {e}")

    return str(out_path)


# ==============================
# ë¬¸ì¥ ë‹¨ìœ„ ìˆ˜ì–´ ì˜ìƒ ì €ì¥ í´ë”
# ==============================
SENTENCE_DIR = MEDIA_ROOT / "sign_sentences"
SENTENCE_DIR.mkdir(parents=True, exist_ok=True)

# ==============================
# ê¸€ë¡œìŠ¤ ì‚¬ì „ ì „ì—­ ë¡œë”©
# ==============================
GLOSS_INDEX = load_gloss_index()

# ---------- gloss_id -> korean_meanings ë§¤í•‘ ë¡œë” ----------
GLOSS_CSV_PATH = BASE_DIR / "data" / "gloss_dictionary_MOCK_1.csv"


def load_gloss_meanings():
    """
    gloss_dictionary_MOCK_1.csvì—ì„œ
    gloss_id -> [korean_meanings ë¦¬ìŠ¤íŠ¸] ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    """
    mapping = {}
    with open(GLOSS_CSV_PATH, "r", encoding="utf-8-sig") as f:
        rdr = csv.DictReader(f)
        for row in rdr:
            gid = (row.get("gloss_id") or "").strip()
            cell = (row.get("korean_meanings") or "").strip()
            if not gid or not cell:
                continue

            # '["ì˜ˆê¸ˆ","ì˜ˆê¸ˆìƒí’ˆ"]' ê°™ì€ ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±
            try:
                obj = ast.literal_eval(cell)
                if isinstance(obj, (list, tuple)):
                    terms = [str(x) for x in obj]
                else:
                    terms = [str(obj)]
            except Exception:
                terms = [cell]

            mapping[gid] = terms
    return mapping


GLOSS_MEANINGS = load_gloss_meanings()
# -----------------------------------------------------------


def concat_videos_ffmpeg(video_paths):
    """ì—¬ëŸ¬ ê°œ ìˆ˜ì–´ mp4ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ ìƒì„±"""
    if not video_paths:
        return None, None

    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".txt", delete=False, encoding="utf-8"
    ) as f:
        for p in video_paths:
            f.write(f"file '{p}'\n")
        list_path = f.name

    out_name = f"sent_{now_ts()}.mp4"
    out_path = SENTENCE_DIR / out_name

    cmd = [
        "ffmpeg", "-y",
        "-f", "concat",
        "-safe", "0",
        "-i", list_path,
        "-c", "copy",
        str(out_path),
    ]

    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    finally:
        try:
            os.remove(list_path)
        except OSError:
            pass

    return out_path, f"/media/sign_sentences/{out_name}"


def convert_to_wav_if_needed(src_path: Path) -> Path:
    """webm/mp3 ë“± â†’ wav(16kHz, mono) ë³€í™˜"""
    if src_path.suffix.lower() == ".wav":
        return src_path

    dst_path = src_path.with_suffix(".wav")

    cmd = [
        "ffmpeg", "-y",
        "-i", str(src_path),
        "-ar", "16000",
        "-ac", "1",
        "-c:a", "pcm_s16le",
        str(dst_path),
    ]

    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return dst_path


def get_media_duration(path: Path) -> float:
    """
    ffprobeë¡œ ë¯¸ë””ì–´(ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤) ê¸¸ì´(ì´ˆ) êµ¬í•˜ê¸°.
    ì‹¤íŒ¨í•˜ë©´ 0.0 ë°˜í™˜.
    """
    try:
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "json",
            str(path),
        ]
        r = subprocess.run(cmd, capture_output=True, text=True)
        if r.returncode != 0:
            return 0.0
        data = json.loads(r.stdout)
        return float(data["format"]["duration"])
    except Exception as e:
        print(f"[Perf] get_media_duration error: {e}")
        return 0.0


def get_audio_duration(path: Path) -> float:
    """ê³¼ê±° ì½”ë“œ í˜¸í™˜ìš© wrapper (ì‹¤ì œë¡œëŠ” get_media_duration ì‚¬ìš©)"""
    return get_media_duration(path)


# ==============================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (APIì—ì„œ í˜¸ì¶œ)
# ==============================
def process_audio_file(django_file, mode=None, session_id=None):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ì—¬
    STT â†’ Gemini(NLP) â†’ tokens â†’ gloss_id â†’ ì˜ìƒ í•©ì„± â†’ latency â†’ snapshot ì €ì¥ â†’ ìµœì¢… ì‘ë‹µ

    mode: "ì§ˆë¬¸" / "ì‘ë‹µ" ë“± í”„ë¡ íŠ¸ì—ì„œ ë„˜ê²¨ì£¼ëŠ” ë°œí™” íƒ€ì… (ì„ íƒ)
    session_id: ì´ë²ˆ ìƒë‹´ ì„¸ì…˜ ì‹ë³„ì (ì„ íƒ)
    """

    # ----------------------------------------
    # 1) ì—…ë¡œë“œ íŒŒì¼ì„ temp í´ë”ì— ì €ì¥
    # ----------------------------------------
    temp_dir = Path(settings.MEDIA_ROOT) / "temp"
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / django_file.name

    with open(temp_path, "wb") as f:
        for chunk in django_file.chunks():
            f.write(chunk)

    # webm â†’ wav ë³€í™˜
    wav_path = convert_to_wav_if_needed(temp_path)

    # wav ê¸¸ì´(ì´ˆ) ì¸¡ì • (STT ì„±ëŠ¥ ë¹„êµìš©)
    audio_sec = get_audio_duration(wav_path)

    latency = {}   # latency ê¸°ë¡ìš©

    # ----------------------------------------
    # 2) STT
    # ----------------------------------------
    t0 = time.perf_counter()
    text = stt_from_file(str(wav_path))   # Whisper STT ê²°ê³¼ (ì›ë¬¸)
    t1 = time.perf_counter()
    latency["stt"] = round((t1 - t0) * 1000, 1)
    latency["stt_load"] = WHISPER_LOAD_MS  # whisper ëª¨ë¸ ë¡œë”© ì‹œê°„(ms, ìµœì´ˆ 1íšŒ)

    
    # ìë§‰/ì¸í’‹ë°•ìŠ¤ì— ì“¸ ë¬¸ì¥ (ì›í•˜ë©´ ì—¬ê¸°ì„œ ì‚´ì§ _norm í•´ë„ ë¨)
    ui_text = _norm(text)

    # STT ì„±ëŠ¥ ë¡œê·¸
    stt_ms = latency["stt"]
    ratio = stt_ms / (audio_sec * 1000 + 1e-6) if audio_sec else 0.0
    print(f"[Perf] audio_sec={audio_sec:.2f}, stt_ms={stt_ms:.1f}, ratio={ratio:.2f}")
    print(f"[DEBUG] STT raw text: {repr(text)}")

    # ----------------------------------------
    # 3) NLP ë‹¨ê³„: clean + gloss + tokens (Gemini)
    # ----------------------------------------
    model = GEMINI_MODEL

    t2 = time.perf_counter()
    clean_text, gloss_list, tokens = nlp_with_gemini(text, model)
    t3 = time.perf_counter()
    latency["nlp"] = round((t3 - t2) * 1000, 1)

    # 3-1) rules.json ê¸°ë°˜ í…ìŠ¤íŠ¸ ì •ê·œí™”
    clean_text = apply_text_normalization(clean_text)

    # ----------------------------------------
    # 4) tokens â†’ ì˜ìƒ ì‹œí€€ìŠ¤ (í† í° ìˆœì„œ ê·¸ëŒ€ë¡œ)
    # ----------------------------------------
    t4 = time.perf_counter()
    video_paths_for_concat, debug_info = build_video_sequence_from_tokens(
        tokens=tokens,
        db_index=GLOSS_INDEX,
        original_text=clean_text,
        # rules=None  # ë„˜ê¸°ì§€ ì•Šìœ¼ë©´ MERGED_RULES ì‚¬ìš©
        include_pause=False,   # pauseë¥¼ ì‹¤ì œ ë¹ˆ í™”ë©´ìœ¼ë¡œ ë„£ê³  ì‹¶ìœ¼ë©´ True
        pause_duration=0.7,
        debug_log=True,        # ë””ë²„ê¹… ë¡œê·¸ ë³´ê³  ì‹¶ìœ¼ë©´ True
    )
    t5 = time.perf_counter()
    latency["mapping"] = round((t5 - t4) * 1000, 1)

    # gloss_ids / gloss_labelsëŠ” "ë©”íƒ€ ì •ë³´" ìš©ë„ë¡œë§Œ ë”°ë¡œ ê³„ì‚°
    gloss_ids = to_gloss_ids(gloss_list, GLOSS_INDEX)

    gloss_labels = []
    for gid in gloss_ids:
        terms = GLOSS_MEANINGS.get(gid) or []
        if terms:
            gloss_labels.append(terms[0])
        else:
            gloss_labels.append(gid)

    # ----------------------------------------
    # 5) ì˜ìƒ í•©ì„±
    # ----------------------------------------
    t6 = time.perf_counter()
    sent_abs, sent_url = concat_videos_ffmpeg(video_paths_for_concat)
    t7 = time.perf_counter()
    latency["synth"] = round((t7 - t6) * 1000, 1)

    # 5-1) í•©ì„±ëœ ë¬¸ì¥ ì˜ìƒ ê¸¸ì´(ì´ˆ) ì¸¡ì •
    video_sec = 0.0
    if sent_abs is not None:
        video_sec = get_media_duration(sent_abs)
        print(f"[Perf] video_sec={video_sec:.2f} s")

    # ê°œë³„ ì˜ìƒ URL ë¦¬ìŠ¤íŠ¸(sign_video_list) êµ¬ì„±
    sign_video_list = []
    for p in video_paths_for_concat:
        p = Path(p)
        try:
            rel = p.relative_to(MEDIA_ROOT)
            url = settings.MEDIA_URL.rstrip("/") + "/" + str(rel).replace("\\", "/")
            sign_video_list.append(url)
        except ValueError:
            sign_video_list.append(str(p))

    # ----------------------------------------
    # 6) ë””ë²„ê·¸ ë¡œê·¸
    # ----------------------------------------
    print("\n========== [DEBUG process_audio_file] ==========")
    print(f"text (STT ì›ë¬¸): {repr(text)}")
    print(f"clean_text: {repr(clean_text)}")
    print(f"gloss_list: {gloss_list}")
    print(f"gloss_ids: {gloss_ids}")
    print(f"gloss_labels: {gloss_labels}")
    print(f"sentence_video_url: {sent_url}")
    print(f"latency_ms: {latency}")
    print(f"video_paths_for_concat: {video_paths_for_concat}")
    print(f"sign_video_list: {sign_video_list}")
    print("===============================================\n")

    # ----------------------------------------
    # 7) latency ë³´ì •: sec ë‹¨ìœ„ + totalê¹Œì§€ ê³„ì‚°
    # ----------------------------------------
    stt_ms      = float(latency.get("stt", 0.0))
    nlp_ms      = float(latency.get("nlp", 0.0))
    mapping_ms  = float(latency.get("mapping", 0.0))
    synth_ms    = float(latency.get("synth", 0.0))
    stt_load_ms = float(WHISPER_LOAD_MS or 0.0)

    total_ms = stt_ms + nlp_ms + mapping_ms + synth_ms

    latency_sec = {
        "stt_load_sec": round(stt_load_ms / 1000.0, 2),
        "stt_sec":     round(stt_ms / 1000.0, 2),
        "nlp_sec":     round(nlp_ms / 1000.0, 2),
        "mapping_sec": round(mapping_ms / 1000.0, 2),
        "synth_sec":   round(synth_ms / 1000.0, 2),
        "total_sec":   round(total_ms / 1000.0, 2),
    }

    print(
        f"[Perf Sentence] STT load: {latency_sec['stt_load_sec']:.2f} s / "
        f"STT: {latency_sec['stt_sec']:.2f} s / "
        f"NLP: {latency_sec['nlp_sec']:.2f} s / "
        f"ë§¤í•‘: {latency_sec['mapping_sec']:.2f} s / "
        f"í•©ì„±: {latency_sec['synth_sec']:.2f} s"
    )
    print(f"[Perf Sentence] ì´í•©: {latency_sec['total_sec']:.2f} s")

    # ----------------------------------------
    current_ts = now_ts()

    result = {
        "ts": current_ts,
        "timestamp": current_ts,
        "session_id": session_id,
        "mode": mode,
        "text": text,
        "clean_text": ui_text,
        "gloss": gloss_list,
        "gloss_ids": gloss_ids,
        "sentence_video_url": sent_url,
        "sign_video_list": sign_video_list,
        "gloss_labels": gloss_labels,
        "audio_sec": audio_sec,
        "video_sec": video_sec,
        "latency_ms": latency,
        "latency_sec": latency_sec,
        "tokens": tokens,        # Geminiê°€ ì¤€ ì „ì²´ í† í° ë¡œê·¸
        "debug_info": debug_info # í† í°ë³„ ë§¤í•‘ ìƒì„¸ (ì›í•˜ë©´ í”„ë¡ íŠ¸ì—ì„œ ì¨ë„ ë¨)
    }

    # ğŸ”¹ gloss vs gloss_labels ë§¤í•‘ ë¡œê·¸ ê¸°ë¡ (mismatchë§Œ ì €ì¥)
    try:
        log_gloss_mapping(
            gloss_list=gloss_list,
            gloss_ids=[str(g) for g in gloss_ids],
            gloss_labels=[str(l) for l in gloss_labels],
            text=clean_text,
            mode=mode,
            session_id=session_id,
            ts=current_ts,
            only_mismatch=True,  # ì „ë¶€ ë³´ê³  ì‹¶ìœ¼ë©´ Falseë¡œ ë³€ê²½
        )
    except Exception as e:
        print(f"[GlossLog] logging error: {e}")

    # ğŸ”¹ ì„¸ì…˜ë³„ ìµœì‹  ê²°ê³¼ë¥¼ ì„œë²„ ìºì‹œì— ì €ì¥ (ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ì—ì„œë„ ê³µìœ )
    if session_id:
        cache_key = f"signance:last_result:{session_id}"
        try:
            cache.set(cache_key, result, timeout=60 * 60)  # 1ì‹œê°„
        except Exception as e:
            print(f"[Cache] save error for {cache_key}: {e}")

    save_api_snapshot(result)
    return result
