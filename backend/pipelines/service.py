# -*- coding: utf-8 -*-
"""
service.py
Django API(/speech_to_sign)ì—ì„œ í˜¸ì¶œë˜ëŠ” íŒŒì´í”„ë¼ì¸ ë˜í¼

ê¸°ëŠ¥:
- ì—…ë¡œë“œëœ audio íŒŒì¼ â†’ wav ë³€í™˜
- STT â†’ clean â†’ gloss ì¶”ì¶œ
- gloss â†’ gloss_id ë§¤í•‘
- gloss_id â†’ mp4 ì˜ìƒ ë¦¬ìŠ¤íŠ¸
- ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ concat
- latency ì¸¡ì •
- ìŠ¤ëƒ…ìƒ·(snapshot) ì €ì¥ (backend/snapshots/api)
- í”„ë¡ íŠ¸ê°€ ì½ëŠ” ìµœì¢… ê²°ê³¼ JSON êµ¬ì„±
"""

import os
import subprocess
import tempfile
from pathlib import Path
import json
import time
import csv
import ast
import contextlib
import wave

from django.conf import settings
from django.core.cache import cache  # ğŸ”¹ ì¶”ê°€

# ============================== #
# pipeline.py ë‚´ë¶€ ê¸°ëŠ¥ import
# ============================== #
from .pipeline import (
    stt_from_file,
    extract_glosses,      # (ë¹„ìƒìš©; ê¸°ë³¸ì€ nlp_with_gemini ì‚¬ìš©)
    to_gloss_ids,
    load_gloss_index,
    _paths_from_ids,
    build_gemini,
    MEDIA_ROOT,
    now_ts,
    OUT_DIR,
    _norm,
    GEMINI_MODEL,
    _local_gloss_rules,
    apply_text_normalization,
    WHISPER_LOAD_MS,
    log_gloss_mapping,    # ğŸ”¹ gloss ë§¤í•‘ ë¡œê·¸
    extract_tokens,
    generate_image_video,
)
# ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ gloss ì¶”ì¶œìš© (Gemini ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©)
from .pipeline import generate_image_video
import re

# ==============================
# API Snapshot ë””ë ‰í† ë¦¬
# ==============================
BASE_DIR = Path(__file__).resolve().parent.parent   # backend/
API_SNAPSHOT_DIR = BASE_DIR / "snapshots" / "api"
API_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)


def nlp_with_gemini(text, model):
    """
    Geminiê°€ {"clean": "...", "gloss": [...]} í˜•íƒœë¡œ ì¤„ ë•Œ
    clean & gloss ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    ì˜¤ë¥˜ ì‹œ fallback = (ì›ë¬¸ ì •ê·œí™”, ë¡œì»¬ gloss)

    ë°˜í™˜:
      clean_text: êµì •ëœ ë¬¸ì¥ (ë˜ëŠ” STT ì •ê·œí™”)
      gloss_list: ì˜ë¯¸ ë‹¨ìœ„ í† í° ë¦¬ìŠ¤íŠ¸
    """
    # 1) Gemini ëª¨ë¸ì´ ì „í˜€ ì¤€ë¹„ ì•ˆ ëœ ê²½ìš° â†’ STT ì •ê·œí™” + ë¡œì»¬ ê·œì¹™ gloss
    if not model:
        clean = _norm(text)
        gloss = _local_gloss_rules(clean)
        return clean, gloss

    try:
        # 2) Gemini í˜¸ì¶œ
        #    system_instruction(build_gemini)ì—ì„œ ì´ë¯¸
        #    {"clean":"â€¦","gloss":["â€¦"]} í˜•ì‹ìœ¼ë¡œ JSONë§Œ ë°˜í™˜í•˜ë„ë¡ ì§€ì‹œí•¨.
        prompt = f"""
ì—­í• : í•œêµ­ì–´ ì „ì‚¬ êµì • + ìˆ˜ì–´ ê¸€ë¡œìŠ¤ ì¶”ì¶œê¸°.
ì•„ë˜ í•œêµ­ì–´ ë¬¸ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ JSON í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ì„¸ìš”.

í˜•ì‹:
{{
  "clean": "<êµì •ëœ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥>",
  "gloss": ["ì˜ë¯¸ë‹¨ì–´1","ì˜ë¯¸ë‹¨ì–´2", ...]
}}

ê·œì¹™:
- "clean": ì›ë¬¸ì˜ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜ ë¶ˆí•„ìš”í•œ ë°˜ë³µ, ë§íˆ¬, ì¡°ì‚¬ ë“±ì„ ì •ë¦¬í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥
- "gloss": ì¡°ì‚¬ë¥¼ ì œê±°í•œ í•µì‹¬ ì˜ë¯¸ ë‹¨ì–´ë“¤ë§Œ, ì¤‘ë³µ ì—†ì´ 1~10ê°œ ì •ë„
- ì¶œë ¥ì€ ìœ„ JSON í•˜ë‚˜ë§Œ, ì¶”ê°€ ì„¤ëª…/ë¬¸ì¥ì€ ë„£ì§€ ë§ ê²ƒ.

ì…ë ¥: "{text}"
"""
        resp = model.generate_content(prompt)

        # build_geminiì—ì„œ response_mime_type="application/json"ì„ ì¤¬ê¸° ë•Œë¬¸ì—
        # resp.textëŠ” JSON ë¬¸ìì—´ì´ì–´ì•¼ í•¨.
        raw = resp.text
        data = json.loads(raw)

        # 3) clean / gloss íŒŒì‹±
        clean = _norm(data.get("clean", text))

        gloss_raw = data.get("gloss", [])
        gloss = []
        for x in gloss_raw:
            s = _norm(str(x))
            if s:
                gloss.append(s)

        # í˜¹ì‹œ glossê°€ ë¹„ì–´ë²„ë ¸ë‹¤ë©´ ìµœì†Œí•œ ë¡œì»¬ ê·œì¹™ì´ë¼ë„ ì‚¬ìš©
        if not gloss:
            gloss = _local_gloss_rules(clean)

        return clean, gloss

    except Exception as e:
        # 4) ì–´ë–¤ ì´ìœ ë¡œë“  Gemini íŒŒì‹± ì‹¤íŒ¨ ì‹œ â†’ ì•ˆì „í•œ fallback
        print(f"[Gemini NLP ERROR] {e}")
        clean = _norm(text)
        gloss = _local_gloss_rules(clean)
        return clean, gloss


def save_api_snapshot(payload: dict) -> str:
    """REST API í˜¸ì¶œ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
    ts = now_ts()
    out_path = API_SNAPSHOT_DIR / f"snapshot_{ts}.json"

    try:
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        print(f"[API Snapshot saved] {out_path}")
    except Exception as e:
        print(f"[API Snapshot ERROR] {e}")

    return str(out_path)


# ==============================
# ë¬¸ì¥ ë‹¨ìœ„ ìˆ˜ì–´ ì˜ìƒ ì €ì¥ í´ë”
# ==============================
SENTENCE_DIR = MEDIA_ROOT / "sign_sentences"
SENTENCE_DIR.mkdir(parents=True, exist_ok=True)

# ==============================
# ê¸€ë¡œìŠ¤ ì‚¬ì „ ì „ì—­ ë¡œë”©
# ==============================
GLOSS_INDEX = load_gloss_index()

# ---------- gloss_id -> korean_meanings ë§¤í•‘ ë¡œë” ----------
GLOSS_CSV_PATH = BASE_DIR / "data" / "gloss_dictionary_MOCK_1.csv"


def load_gloss_meanings():
    """
    gloss_dictionary_MOCK_1.csvì—ì„œ
    gloss_id -> [korean_meanings ë¦¬ìŠ¤íŠ¸] ë§¤í•‘ì„ ë§Œë“ ë‹¤.
    """
    mapping = {}
    with open(GLOSS_CSV_PATH, "r", encoding="utf-8-sig") as f:
        rdr = csv.DictReader(f)
        for row in rdr:
            gid = (row.get("gloss_id") or "").strip()
            cell = (row.get("korean_meanings") or "").strip()
            if not gid or not cell:
                continue

            # '["ì˜ˆê¸ˆ","ì˜ˆê¸ˆìƒí’ˆ"]' ê°™ì€ ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±
            try:
                obj = ast.literal_eval(cell)
                if isinstance(obj, (list, tuple)):
                    terms = [str(x) for x in obj]
                else:
                    terms = [str(obj)]
            except Exception:
                terms = [cell]

            mapping[gid] = terms
    return mapping


GLOSS_MEANINGS = load_gloss_meanings()
# -----------------------------------------------------------


def concat_videos_ffmpeg(video_paths):
    """ì—¬ëŸ¬ ê°œ ìˆ˜ì–´ mp4ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ ë¬¸ì¥ ë‹¨ìœ„ ì˜ìƒ ìƒì„±"""
    if not video_paths:
        return None, None

    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".txt", delete=False, encoding="utf-8"
    ) as f:
        for p in video_paths:
            f.write(f"file '{p}'\n")
        list_path = f.name

    out_name = f"sent_{now_ts()}.mp4"
    out_path = SENTENCE_DIR / out_name

    cmd = [
        "ffmpeg", "-y",
        "-f", "concat",
        "-safe", "0",
        "-i", list_path,
        "-c", "copy",
        str(out_path),
    ]

    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    finally:
        try:
            os.remove(list_path)
        except OSError:
            pass

    return out_path, f"/media/sign_sentences/{out_name}"


def convert_to_wav_if_needed(src_path: Path) -> Path:
    """webm/mp3 ë“± â†’ wav(16kHz, mono) ë³€í™˜"""
    if src_path.suffix.lower() == ".wav":
        return src_path

    dst_path = src_path.with_suffix(".wav")

    cmd = [
        "ffmpeg", "-y",
        "-i", str(src_path),
        "-ar", "16000",
        "-ac", "1",
        "-c:a", "pcm_s16le",
        str(dst_path),
    ]

    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return dst_path


def get_media_duration(path: Path) -> float:
    """
    ffprobeë¡œ ë¯¸ë””ì–´(ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤) ê¸¸ì´(ì´ˆ) êµ¬í•˜ê¸°.
    ì‹¤íŒ¨í•˜ë©´ 0.0 ë°˜í™˜.
    """
    try:
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "json",
            str(path),
        ]
        r = subprocess.run(cmd, capture_output=True, text=True)
        if r.returncode != 0:
            return 0.0
        data = json.loads(r.stdout)
        return float(data["format"]["duration"])
    except Exception as e:
        print(f"[Perf] get_media_duration error: {e}")
        return 0.0


def get_audio_duration(path: Path) -> float:
    """ê³¼ê±° ì½”ë“œ í˜¸í™˜ìš© wrapper (ì‹¤ì œë¡œëŠ” get_media_duration ì‚¬ìš©)"""
    return get_media_duration(path)


# ==============================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (APIì—ì„œ í˜¸ì¶œ)
# ==============================
def process_audio_file(django_file, mode=None, session_id=None):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ì—¬
    STT â†’ NLP â†’ gloss_id â†’ ì˜ìƒ í•©ì„± â†’ latency â†’ snapshot ì €ì¥ â†’ ìµœì¢… ì‘ë‹µ

    mode: "ì§ˆë¬¸" / "ì‘ë‹µ" ë“± í”„ë¡ íŠ¸ì—ì„œ ë„˜ê²¨ì£¼ëŠ” ë°œí™” íƒ€ì… (ì„ íƒ)
    session_id: ì´ë²ˆ ìƒë‹´ ì„¸ì…˜ ì‹ë³„ì (ì„ íƒ)from .pipeline import
    """

    # ----------------------------------------
    # 1) ì—…ë¡œë“œ íŒŒì¼ì„ temp í´ë”ì— ì €ì¥
    # ----------------------------------------
    temp_dir = Path(settings.MEDIA_ROOT) / "temp"
    temp_dir.mkdir(parents=True, exist_ok=True)
    temp_path = temp_dir / django_file.name

    with open(temp_path, "wb") as f:
        for chunk in django_file.chunks():
            f.write(chunk)

    # webm â†’ wav ë³€í™˜
    wav_path = convert_to_wav_if_needed(temp_path)

    # wav ê¸¸ì´(ì´ˆ) ì¸¡ì • (STT ì„±ëŠ¥ ë¹„êµìš©)
    audio_sec = get_audio_duration(wav_path)

    latency = {}   # latency ê¸°ë¡ìš©

    # ----------------------------------------
    # 2) STT
    # ----------------------------------------
    t0 = time.perf_counter()
    text = stt_from_file(str(wav_path))   # Whisper STT ê²°ê³¼ (ì›ë¬¸)
    t1 = time.perf_counter()
    latency["stt"] = round((t1 - t0) * 1000, 1)
    latency["stt_load"] = WHISPER_LOAD_MS  # whisper ëª¨ë¸ ë¡œë”© ì‹œê°„(ms, ìµœì´ˆ 1íšŒ)

    # STT ì„±ëŠ¥ ë¡œê·¸
    stt_ms = latency["stt"]
    ratio = stt_ms / (audio_sec * 1000 + 1e-6) if audio_sec else 0.0
    print(f"[Perf] audio_sec={audio_sec:.2f}, stt_ms={stt_ms:.1f}, ratio={ratio:.2f}")
    print(f"[DEBUG] STT raw text: {repr(text)}")

    # 3) NLP ë‹¨ê³„: clean + gloss í›„ë³´ (nlp_with_geminiëŠ” ì¼ë‹¨ ìœ ì§€)
    model = GEMINI_MODEL

    t2 = time.perf_counter()
    clean_text, _gloss_dummy = nlp_with_gemini(text, model)
    t3 = time.perf_counter()
    latency["nlp"] = round((t3 - t2) * 1000, 1)

    # 3-1) rules.json ê¸°ë°˜ í…ìŠ¤íŠ¸ ì •ê·œí™”
    clean_text = apply_text_normalization(clean_text)

    # ğŸ”¹ 3-2) Gemini í† í° ì¶”ì¶œ: gloss / image / pause ëª¨ë‘ í¬í•¨
    tokens = extract_tokens(clean_text, model=model)

    # ğŸ”¹ 3-3) íŒŒì´í”„ë¼ì¸ì—ì„œ ì“¸ gloss_list / image_tokens ë¶„ë¦¬
    gloss_list = [
        t["text"]
        for t in tokens
        if isinstance(t, dict)
        and t.get("type", "gloss") == "gloss"
        and (t.get("text") or "").strip()
    ]

    image_tokens = [
        (t.get("text") or "").strip()
        for t in tokens
        if isinstance(t, dict)
        and t.get("type") == "image"
        and (t.get("text") or "").strip()
    ]

    # ----------------------------------------
    # 4) gloss â†’ gloss_id ë§¤í•‘
    # ----------------------------------------
    t4 = time.perf_counter()
    gloss_ids = to_gloss_ids(gloss_list, GLOSS_INDEX)
    video_paths = _paths_from_ids(gloss_ids)
    t5 = time.perf_counter()
    latency["mapping"] = round((t5 - t4) * 1000, 1)

    # 4-1) ìˆ«ì/ì´ë¯¸ì§€ í† í°ì— ëŒ€í•œ fallback: ì´ë¯¸ì§€ ê¸°ë°˜ ë™ì˜ìƒ ìƒì„±
    # 4-1) í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ í† í° ì²˜ë¦¬: image í† í° + ìˆ«ì íŒ¨í„´ fallback
    extra_video_paths = []

    # (1) Geminiê°€ type="image"ë¡œ ì¤€ í† í° ìš°ì„  ì²˜ë¦¬
    for t in image_tokens:
        try:
            img_mp4 = generate_image_video(t, duration=1.5)
            extra_video_paths.append(img_mp4)
            print(f"[ImageToken Video] token={t} -> {img_mp4}")
        except Exception as e:
            print(f"[ImageToken Video ERROR] token={t}: {e}")

    # (2) í˜¹ì‹œ imageë¡œ ì•ˆ ì°í˜”ì§€ë§Œ ìˆ«ì í˜•íƒœì¸ glossë“¤ì€ fallbackìœ¼ë¡œ ì²˜ë¦¬
    num_pattern = re.compile(r"^\d+[ê°€-í£%ë…„ì›”ì„¸ì›ë§Œì›ì–µê°œì›”íšŒ]*$")

    for tok in gloss_list or []:
        t = _norm(str(tok))
        if not t:
            continue

        # ì´ë¯¸ image_tokensì—ì„œ ì²˜ë¦¬ëœ ê°’ì´ë©´ ìƒëµ
        if t in image_tokens:
            continue

        if num_pattern.match(t):
            try:
                img_mp4 = generate_image_video(t, duration=1.5)
                extra_video_paths.append(img_mp4)
                print(f"[Fallback ImageVideo] token={t} -> {img_mp4}")
            except Exception as e:
                print(f"[Fallback ImageVideo ERROR] token={t}: {e}")

    # ìµœì¢… í•©ì„±ì— ì“¸ ê²½ë¡œë“¤ (ê¸°ì¡´ ìˆ˜ì–´ ì˜ìƒ + ìˆ«ì ì´ë¯¸ì§€ ì˜ìƒ)
    video_paths_for_concat = video_paths + extra_video_paths

    # gloss_id â†’ í•œê¸€ meaning ëŒ€í‘œ ë ˆì´ë¸”
    gloss_labels = []
    for gid in gloss_ids:
        terms = GLOSS_MEANINGS.get(gid) or []
        if terms:
            gloss_labels.append(terms[0])
        else:
            gloss_labels.append(gid)

    # ----------------------------------------
    # 5) ì˜ìƒ í•©ì„±
    # ----------------------------------------
    t6 = time.perf_counter()
    sent_abs, sent_url = concat_videos_ffmpeg(video_paths_for_concat)
    t7 = time.perf_counter()
    latency["synth"] = round((t7 - t6) * 1000, 1)

    # 5-1) í•©ì„±ëœ ë¬¸ì¥ ì˜ìƒ ê¸¸ì´(ì´ˆ) ì¸¡ì •
    video_sec = 0.0
    if sent_abs is not None:
        video_sec = get_media_duration(sent_abs)
        print(f"[Perf] video_sec={video_sec:.2f} s")

    # ê°œë³„ ì˜ìƒ URL ë¦¬ìŠ¤íŠ¸(sign_video_list) êµ¬ì„±
    sign_video_list = []
    for p in video_paths_for_concat:
        p = Path(p)
        try:
            rel = p.relative_to(MEDIA_ROOT)
            url = settings.MEDIA_URL.rstrip("/") + "/" + str(rel).replace("\\", "/")
            sign_video_list.append(url)
        except ValueError:
            sign_video_list.append(str(p))

    # ----------------------------------------
    # 6) ë””ë²„ê·¸ ë¡œê·¸
    # ----------------------------------------
    print("\n========== [DEBUG process_audio_file] ==========")
    print(f"text (STT ì›ë¬¸): {repr(text)}")
    print(f"clean_text: {repr(clean_text)}")
    print(f"gloss_list: {gloss_list}")
    print(f"gloss_ids: {gloss_ids}")
    print(f"gloss_labels: {gloss_labels}")
    print(f"video_paths: {video_paths}")
    print(f"sentence_video_url: {sent_url}")
    print(f"latency_ms: {latency}")
    print(f"video_paths_for_concat: {video_paths_for_concat}")
    print(f"sign_video_list: {sign_video_list}")
    print("===============================================\n")

    # ----------------------------------------
    # 7) latency ë³´ì •: sec ë‹¨ìœ„ + totalê¹Œì§€ ê³„ì‚°
    # ----------------------------------------
    stt_ms     = float(latency.get("stt", 0.0))
    nlp_ms     = float(latency.get("nlp", 0.0))
    mapping_ms = float(latency.get("mapping", 0.0))
    synth_ms   = float(latency.get("synth", 0.0))
    stt_load_ms = float(WHISPER_LOAD_MS or 0.0)

    total_ms = stt_ms + nlp_ms + mapping_ms + synth_ms

    latency_sec = {
        "stt_load_sec": round(stt_load_ms / 1000.0, 2),
        "stt_sec":     round(stt_ms / 1000.0, 2),
        "nlp_sec":     round(nlp_ms / 1000.0, 2),
        "mapping_sec": round(mapping_ms / 1000.0, 2),
        "synth_sec":   round(synth_ms / 1000.0, 2),
        "total_sec":   round(total_ms / 1000.0, 2),
    }

    print(
        f"[Perf Sentence] STT load: {latency_sec['stt_load_sec']:.2f} s / "
        f"STT: {latency_sec['stt_sec']:.2f} s / "
        f"NLP: {latency_sec['nlp_sec']:.2f} s / "
        f"ë§¤í•‘: {latency_sec['mapping_sec']:.2f} s / "
        f"í•©ì„±: {latency_sec['synth_sec']:.2f} s"
    )
    print(f"[Perf Sentence] ì´í•©: {latency_sec['total_sec']:.2f} s")

    # ----------------------------------------
    current_ts = now_ts()

    result = {
        "ts": current_ts,
        "timestamp": current_ts,
        "session_id": session_id,
        "mode": mode,
        "text": text,
        "clean_text": clean_text,
        "gloss": gloss_list,
        "gloss_ids": gloss_ids,
        "sentence_video_url": sent_url,
        "sign_video_list": sign_video_list,
        "gloss_labels": gloss_labels,
        "audio_sec": audio_sec,
        "video_sec": video_sec,
        "latency_ms": latency,
        "latency_sec": latency_sec,
        "tokens": tokens,
    }

    # ğŸ”¹ gloss vs gloss_labels ë§¤í•‘ ë¡œê·¸ ê¸°ë¡ (mismatchë§Œ ì €ì¥)
    try:
        log_gloss_mapping(
            gloss_list=gloss_list,
            gloss_ids=[str(g) for g in gloss_ids],
            gloss_labels=[str(l) for l in gloss_labels],
            text=clean_text,
            mode=mode,
            session_id=session_id,
            ts=current_ts,
            only_mismatch=True,  # ì „ë¶€ ë³´ê³  ì‹¶ìœ¼ë©´ Falseë¡œ ë³€ê²½
        )
    except Exception as e:
        print(f"[GlossLog] logging error: {e}")

    # ğŸ”¹ ì„¸ì…˜ë³„ ìµœì‹  ê²°ê³¼ë¥¼ ì„œë²„ ìºì‹œì— ì €ì¥ (ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ì—ì„œë„ ê³µìœ )
    if session_id:
        cache_key = f"signance:last_result:{session_id}"
        try:
            cache.set(cache_key, result, timeout=60 * 60)  # 1ì‹œê°„
        except Exception as e:
            print(f"[Cache] save error for {cache_key}: {e}")

    save_api_snapshot(result)
    return result
