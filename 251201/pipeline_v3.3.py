# -*- coding: utf-8 -*-

# ==============================================================================
# [SECTION 0] Imports & Configuration
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸, ê²½ë¡œ ì„¤ì •, API í‚¤ ë¡œë“œ, ì „ì—­ ì„¤ì •
# ==============================================================================
import os
import csv
import re
import json
import ast
import unicodedata
import difflib
import wave
import threading
import time
import sys
from datetime import datetime
from pathlib import Path
import shutil
import subprocess
import tempfile

import sounddevice as sd                # ë§ˆì´í¬ ì…ë ¥
import whisper                          # STT
from dotenv import load_dotenv          # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# [ì¶”ê°€] ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from PIL import Image, ImageDraw, ImageFont

# Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import google.generativeai as genai
except Exception:
    genai = None

# 1. .env íŒŒì¼ ë¡œë“œ
if not load_dotenv():
    print("âš ï¸  .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# 3. í‚¤ í™•ì¸
if not GOOGLE_API_KEY:
    print("âŒ  [Error] GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)
else:
    print(f"âœ…  API Key ë¡œë“œ ì™„ë£Œ (Len: {len(GOOGLE_API_KEY)})")

# 4. ê²½ë¡œ ì„¤ì •
try:
    ROOT_DIR = Path(__file__).resolve().parent
except NameError:
    ROOT_DIR = Path(os.getcwd())

DATA_DIR = ROOT_DIR / "data"
OUT_DIR = ROOT_DIR / "snapshots14"
GLOSS_DICT_PATH = DATA_DIR / "gloss_dictionary_MOCK.csv"
RULES_JSON_PATH = DATA_DIR / "rules.json"
GLOSS_MP4_DIR = DATA_DIR / "service"

VIDEO_OUT_DIR = ROOT_DIR / "vd_output"
VIDEO_OUT_DIR.mkdir(exist_ok=True)


# í´ë” ìë™ ìƒì„±
OUT_DIR.mkdir(exist_ok=True)

# 5. ëª¨ë¸ ë° ì˜¤ë””ì˜¤ ì„¤ì •
GEMINI_MODEL_NAME = "models/gemini-2.5-flash"
WHISPER_MODEL_NAME = "small"
WHISPER_LANG = "ko"

CHUNK = 1024        # ì½œë°±ë‹¹ í”„ë ˆì„ ìˆ˜
DEBOUNCE_SEC = 0.5  # Enter ì—°íƒ€ ë°©ì§€
ALWAYS_RETURN_ID = True    # ë§¤í•‘ ì‹¤íŒ¨ ì‹œì—ë„ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ID í•˜ë‚˜ëŠ” ì„ íƒ


# ==============================================================================
# [SECTION 1] Common Utilities
# í…ìŠ¤íŠ¸ ì •ê·œí™”, íƒ€ì„ìŠ¤íƒ¬í”„ ë“± ê³µí†µ í—¬í¼ í•¨ìˆ˜
# ==============================================================================
def _norm(s: str) -> str:
    """ì „ê°/ë°˜ê° í†µì¼ + ì–‘ ë ê³µë°± ì œê±° + ë‚´ë¶€ ë‹¤ì¤‘ ê³µë°±ì„ 1ì¹¸ìœ¼ë¡œ ì¶•ì†Œ."""
    s = unicodedata.normalize("NFKC", s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def _first_word(phrase: str) -> str:
    """ë¬¸ì¥ì—ì„œ ì²« ë‹¨ì–´ë§Œ ì¶”ì¶œ(ê¸€ë¡œìŠ¤ëŠ” ë‹¨ì–´ 1ê°œë¼ëŠ” ì „ì œ ìœ ì§€ìš©)."""
    s = _norm(phrase)
    return s.split()[0] if s else ""

def _nospace(s: str) -> str:
    """ê³µë°±/ê¸°í˜¸ ì œê±° í›„ ë¹„êµìš© í‚¤ ìƒì„±."""
    return re.sub(r"[^\wê°€-í£]", "", re.sub(r"\s+", "", _norm(s)))

def now_ts() -> str:
    """í˜„ì¬ ì‹œê°ì„ YYYYmmdd_HHMMSS ë¬¸ìì—´ë¡œ ë°˜í™˜."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


# ==============================================================================
# [SECTION 2] Input (Audio Capture)
# ë§ˆì´í¬ ì¥ì¹˜ ì„¤ì •, ìŠ¤íŠ¸ë¦¼ ì½œë°±, ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘
# ==============================================================================
frames = []                       # ì˜¤ë””ì˜¤ ì¡°ê°(ë°”ì´íŠ¸) ëˆ„ì 
frames_lock = threading.Lock()
_last_frame_idx = 0
ACTUAL_RATE = None               # ì‹¤ì œ ì¥ì¹˜ ìƒ˜í”Œë ˆì´íŠ¸
sd_stream = None

def list_devices():
    """í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ë””ë°”ì´ìŠ¤ ëª©ë¡ ì¶œë ¥(ë””ë²„ê¹…ìš©)."""
    print("[Audio] Listing devices â€¦")
    for i, dev in enumerate(sd.query_devices()):
        print(
            f"  #{i}: {dev['name']} | inputs={dev['max_input_channels']} | "
            f"defaultSR={int(dev['default_samplerate'])}"
        )

def _audio_cb(indata, frames_cnt, time_info, status):
    """sounddevice RawInputStream ì½œë°±: ë“¤ì–´ì˜¨ ë°”ì´íŠ¸ë¥¼ frames ë¦¬ìŠ¤íŠ¸ì— ê·¸ëŒ€ë¡œ ëˆ„ì ."""
    if status:
        print(f"[Audio] status: {status}")
    with frames_lock:
        frames.append(bytes(indata))

def open_input_stream():
    """ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¡œ RawInputStream ì—´ê¸°."""
    global ACTUAL_RATE
    info = sd.query_devices(kind="input")
    sr = int(info["default_samplerate"]) if info and info["default_samplerate"] else 16000
    ACTUAL_RATE = sr
    print(f"[Audio] Using device='{info['name']}' @ {sr} Hz")
    return sd.RawInputStream(
        samplerate=sr,
        channels=1,
        dtype="int16",
        blocksize=CHUNK,
        callback=_audio_cb,
    )

def cut_delta_blob() -> bytes:
    """
    frames ë¦¬ìŠ¤íŠ¸ì—ì„œ 'ì§ì „ ìŠ¤ëƒ…ìƒ· ì´í›„ ~ í˜„ì¬ê¹Œì§€' êµ¬ê°„ë§Œ ì˜ë¼ì„œ ë°˜í™˜.
    (delta ëª¨ë“œ)
    """
    global _last_frame_idx
    with frames_lock:
        cur = len(frames)
        if cur <= _last_frame_idx:
            return b""
        blob = b"".join(frames[_last_frame_idx:cur])
        _last_frame_idx = cur
        return blob


# ==============================================================================
# [SECTION 3] NLP (Natural Language Processing)
# Gemini ëª¨ë¸ ì„¤ì •, í…ìŠ¤íŠ¸ ë¶„ì„ ë° í† í° ì¶”ì¶œ
# ==============================================================================
def build_gemini():
    """í™˜ê²½ë³€ìˆ˜ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¤€ë¹„ë˜ë©´ Gemini ëª¨ë¸ì„ ìƒì„±, ì•„ë‹ˆë©´ None."""
    if not GOOGLE_API_KEY or genai is None:
        return None

    genai.configure(api_key=GOOGLE_API_KEY)
    
    sys_prompt = f"""
    ë‹¹ì‹ ì€ 'ì²­ê°ì¥ì• ì¸ì„ ìœ„í•œ ì „ë¬¸ ìˆ˜ì–´(KSL) í†µì—­ì‚¬'ì…ë‹ˆë‹¤. 
    ì…ë ¥ëœ ë¬¸ì¥ì„ ë‹¨ìˆœ ë²ˆì—­í•˜ì§€ ë§ê³ , 'ë†ë¬¸í™”(Deaf Culture)'ì™€ 'í•œêµ­ìˆ˜ì–´ ë¬¸ë²•'ì— ë§ì¶° ì˜ë¯¸ë¥¼ ì¬êµ¬ì„±(Paraphrasing)í•˜ì‹­ì‹œì˜¤.

    [í•µì‹¬ ì‘ì—… ì›ì¹™]
    1. ìˆ˜ì§€í•œêµ­ì–´(SK) ê¸ˆì§€: í•œêµ­ì–´ì˜ ì–´ìˆœì´ë‚˜ ë¬¸ë²• ìš”ì†Œ(ì¡°ì‚¬, ì–´ë¯¸)ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¼ê°€ì§€ ë§ˆì‹­ì‹œì˜¤.
    2. ì˜ë¯¸ ì¤‘ì‹¬ ë²ˆì—­: ë¬¸ì¥ì˜ 'í•µì‹¬ ì˜ë„'ë¥¼ íŒŒì•…í•˜ì—¬ ê°€ì¥ ì§ê´€ì ì¸ ë‹¨ì–´ë“¤ì˜ ë‚˜ì—´ë¡œ ë°”ê¾¸ì‹­ì‹œì˜¤.
    3. ë©”íƒ€ ë°œí™” ì‚­ì œ: "ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤", "ë§ì”€ë“œë¦¬ìë©´" ë“± ì •ë³´ê°€ê°€ ì—†ëŠ” ë©˜íŠ¸ëŠ” ê³¼ê°íˆ ì‚­ì œí•˜ì‹­ì‹œì˜¤.
       - ë‹¨, 'ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°‘ìŠµë‹ˆë‹¤', 'ê³ ë§™ìŠµë‹ˆë‹¤(ê°ì‚¬í•©ë‹ˆë‹¤)', 'ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤' ë“± ì‚¬íšŒì  ê´€ê³„ë¥¼ ë§ºëŠ” ì¸ì‚¬ë§ì€ ì‚­ì œí•˜ì§€ ë§ê³  ë°˜ë“œì‹œ ìˆ˜ì–´ ë‹¨ì–´ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.
    4. í•œêµ­ì–´ ì „ìš© ì¶œë ¥ (Korean Only): 
       - ê²°ê³¼ JSONì˜ 'text' í•„ë“œ ê°’ì—ëŠ” 'ë°˜ë“œì‹œ í•œêµ­ì–´ ë˜ëŠ” ìˆ«ì'ë§Œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.
       - ì˜ì–´ ë‹¨ì–´(ì˜ˆ: 'Limit', 'Bank')ê°€ í¬í•¨ë˜ë©´ ë¬´ì¡°ê±´ í•œêµ­ì–´ ëœ»ìœ¼ë¡œ ë²ˆì—­í•˜ì—¬ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.


    [ë¬¸ë²• ë° êµ¬ì¡° ê·œì¹™ (Strict Rules)]
    
    1. í™”ì œ-ì„œìˆ  êµ¬ì¡° (Topic-Comment):
       - ë¬¸ì¥ ë§¨ ì•ì— [ì‹œê°„] -> [ì¥ì†Œ] -> [í™”ì œ(Topic)]ë¥¼ ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.
       - í™”ì œì™€ ì„œìˆ ë¶€ ì‚¬ì´ì—ëŠ” ë°˜ë“œì‹œ `type: "pause"`ë¥¼ ì‚½ì…í•˜ì—¬ ì‹œê°ì  í˜¸í¡ì„ ì£¼ì‹­ì‹œì˜¤.
       - ì˜ˆ: "ì–´ì œ ì§‘ì—ì„œ ë°¥ì„ ë¨¹ì—ˆë‹¤" -> [ì–´ì œ], [ì§‘], [PAUSE], [ë°¥], [ë¨¹ë‹¤]
    
    2. ìˆ˜ëŸ‰ì‚¬ ë° ìˆ˜ì‹ì–´ í›„ì¹˜ (Post-position):
       - [ìˆ˜ëŸ‰]: 'í•œ ì‚¬ëŒ', 'ë‘ ê°œì˜ ê³„ì¢Œ'ëŠ” ë°˜ë“œì‹œ [ëª…ì‚¬] + [ìˆ˜ëŸ‰] ìˆœì„œë¡œ ë³€ê²½í•˜ì‹­ì‹œì˜¤. 
         -> "í•œ ì‚¬ëŒ" (X) -> [ì‚¬ëŒ], [1ëª…(ì´ë¯¸ì§€)] (O)
       - [ë¶€ì •ì–´]: ì„œìˆ ì–´ ë’¤ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤. (ì˜ˆ: [ê°€ë‹¤], [ì•ˆí•˜ë‹¤])
       - [í˜•ìš©ì‚¬]: ëª…ì‚¬ ë’¤ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤. (ì˜ˆ: [ë”¸], [ì˜ˆì˜ë‹¤])

    3. ìˆ«ì ë° ë‹¨ìœ„ ì²˜ë¦¬ (ì´ë¯¸ì§€í™”):
       - ì˜¤ì¸ì‹ ë°©ì§€ë¥¼ ìœ„í•´ ìˆ«ìê°€ í¬í•¨ëœ ëª¨ë“  í‘œí˜„ì€ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
       - ê´€í˜•ì‚¬ 'í•œ, ë‘, ì„¸'ëŠ” ë°˜ë“œì‹œ ì•„ë¼ë¹„ì•„ ìˆ«ì '1, 2, 3'ìœ¼ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.
       - % (í¼ì„¼íŠ¸): '[{{ "text": "3.5", "type": "image" }}, {{ "text": "í¼ì„¼íŠ¸", "type": "gloss" }}]'
       - %p (í¼ì„¼íŠ¸ í¬ì¸íŠ¸): '[{{ "text": "0.5", "type": "image" }}, {{ "text": "í¼ì„¼íŠ¸", "type": "gloss" }}, {{ "text": "í¬ì¸íŠ¸", "type": "gloss" }}]'
       - ì—° ì´ìœ¨: 'ì—°'ì€ `[1ë…„]` ìˆ˜ì–´ë¡œ, ì´ìœ¨ì€ '[í¼ì„¼íŠ¸]'ë¡œ ì²˜ë¦¬.

    4. ì–´íœ˜ ë‹¨ìˆœí™” (Vocabulary Simplification):
       - ì–´ë ¤ìš´ í•œìì–´, ì „ë¬¸ ìš©ì–´ëŠ” ê¸°ì´ˆì ì¸ ìˆ˜ì–´ ë‹¨ì–´ì˜ ì¡°í•©ìœ¼ë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
       - ì˜ˆ: "ì£¼íƒë‹´ë³´ëŒ€ì¶œ" -> '[ì§‘]', '[ë§¡ê¸°ë‹¤]', '[ëˆ]', '[ë¹Œë¦¬ë‹¤]'
       - ì˜ˆ: "ìš°ëŒ€ê¸ˆë¦¬" -> '[íŠ¹ë³„]', '[ì´ì]'

    [Few-shot Examples]

    ì…ë ¥: "ì´ ìƒí’ˆì€ í•œ ì‚¬ëŒë‹¹ í•˜ë‚˜ì˜ ê³„ì¢Œë§Œ ê°œì„¤ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    ì¶œë ¥:
    {{
        "cleaned": "ìƒí’ˆ ì´ê²ƒ ì‚¬ëŒ 1ëª… ê³„ì¢Œ 1ê°œ ê°œì„¤ ê°€ëŠ¥",
        "tokens": [
            {{ "text": "ìƒí’ˆ", "type": "gloss" }},
            {{ "text": "ì´ê²ƒ", "type": "gloss" }},
            {{ "text": "PAUSE", "type": "pause" }},
            {{ "text": "ì‚¬ëŒ", "type": "gloss" }},
            {{ "text": "1ëª…", "type": "image" }},
            {{ "text": "ê³„ì¢Œ", "type": "gloss" }},
            {{ "text": "1ê°œ", "type": "image" }},
            {{ "text": "ê°œì„¤", "type": "gloss" }},
            {{ "text": "ê°€ëŠ¥", "type": "gloss" }}
        ]
    }}

    ì…ë ¥: "ê¸ˆë¦¬ëŠ” ì—° 3.5%í¬ì¸íŠ¸ ìš°ëŒ€ ì ìš©ë©ë‹ˆë‹¤."
    ì¶œë ¥:
    {{
        "cleaned": "ê¸ˆë¦¬ 1ë…„ 3.5 í¼ì„¼íŠ¸ ì ìˆ˜ íŠ¹ë³„ ì ìš©",
        "tokens": [
            {{ "text": "ê¸ˆë¦¬", "type": "gloss" }},
            {{ "text": "PAUSE", "type": "pause" }},
            {{ "text": "1ë…„", "type": "gloss" }},
            {{ "text": "3.5", "type": "image" }},
            {{ "text": "í¼ì„¼íŠ¸", "type": "gloss" }},
            {{ "text": "ì ìˆ˜", "type": "gloss" }},
            {{ "text": "íŠ¹ë³„", "type": "gloss" }},
            {{ "text": "ì ìš©", "type": "gloss" }}
        ]
    }}
    5. ë²”ìœ„ í‘œí˜„ (Range):
       - 'ì´ìƒ/ì´í•˜/ì´ˆê³¼/ë¯¸ë§Œ'ì€ ì˜¤ì—­ ë°©ì§€ë¥¼ ìœ„í•´ ë°˜ë“œì‹œ 'ë¶€í„°(~ë¶€í„°)'ì™€ 'ê¹Œì§€(~ê¹Œì§€)'ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.
       - ì…ë ¥: "2.5% ì´ìƒ" -> '[{{ "text": "2.5", "type": "image" }}, {{ "text": "í¼ì„¼íŠ¸", "type": "gloss" }}, {{ "text": "ë¶€í„°", "type": "gloss" }}]'
       - ì…ë ¥: "3.5% ì´í•˜" -> '[{{ "text": "3.5", "type": "image" }}, {{ "text": "í¼ì„¼íŠ¸", "type": "gloss" }}, {{ "text": "ê¹Œì§€", "type": "gloss" }}]'
       - ì…ë ¥: "18ì„¸~30ì„¸" -> '[{{ "text": "18ì„¸", "type": "image" }}, {{ "text": "ë¶€í„°", "type": "gloss" }}, {{ "text": "30ì„¸", "type": "image" }}, {{ "text": "ê¹Œì§€", "type": "gloss" }}]'

    [ì¶œë ¥ í¬ë§· (JSON Only)]
    ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    """

    return genai.GenerativeModel(
        GEMINI_MODEL_NAME,
        system_instruction=sys_prompt,
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0.2,
        },
    )

def extract_glosses(text: str, model) -> list[dict]:
    """
    ë¬¸ì¥ì„ ë¶„ì„í•˜ì—¬ í† í° ë¦¬ìŠ¤íŠ¸(dict) ë°˜í™˜.
    ë°˜í™˜ ì˜ˆì‹œ: [{'text': 'ë‚˜ì´', 'type': 'gloss'}, {'text': '18ì„¸', 'type': 'image'}]
    """
    clean = _norm(text)
    if not clean:
        return []

    # 1) Gemini ì‚¬ìš©
    if model:
        try:
            parts = [{"role": "user", "parts": [clean]}]
            resp = model.generate_content(parts)
            # ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¶€ë¶„ë§Œ íŒŒì‹± ì‹œë„
            try:
                obj = json.loads(resp.text)
            except:
                # ê°€ë” ë§ˆí¬ë‹¤ìš´ ```json ... ``` ìœ¼ë¡œ ê°ì‹¸ì„œ ì¤„ ë•Œ ì²˜ë¦¬
                json_str = re.search(r"\{.*\}", resp.text, re.DOTALL)
                if json_str:
                    obj = json.loads(json_str.group())
                else:
                    obj = {}
            
            # tokens ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return obj.get("tokens", [])
            
        except Exception as e:
            print(f"[Gemini Error] {e}")
            pass

    # 2) ë¡œì»¬ í´ë°± (Gemini ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ê¸€ë¡œìŠ¤ë¡œ ì²˜ë¦¬)
    # ê¸°ì¡´ ë¡œì§ì„ ìœ ì§€í•˜ë˜ í¬ë§·ë§Œ ë§ì¶¤
    tokens = re.findall(r"\d+(?:ì–µì›|ì–µ\s*ì›|ê°œì›”|ë…„)|[ê°€-í£A-Za-z]+", clean)
    return [{"text": _first_word(t), "type": "gloss"} for t in tokens if _first_word(t)]


# ==============================================================================
# [SECTION 4] Query & Resolution (Search Engine)
# CSV ì‚¬ì „ ë¡œë“œ, ë£° ê¸°ë°˜ ID ë§¤í•‘, íŒŒì¼ ê²½ë¡œ ë³€í™˜
# ==============================================================================
# [ì¶”ê°€] ì „ì—­ ë³€ìˆ˜ë¡œ ì˜ìƒ ìœ„ì¹˜ ì§€ë„ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì„ ì–¸
VIDEO_PATH_INDEX = {} 

def build_video_index(root_dir: Path):
    """
    [ì¤‘ìš”] í•˜ìœ„ í´ë”(fi, li ë“±)ë¥¼ í¬í•¨í•œ ëª¨ë“  mp4 íŒŒì¼ì„ ê²€ìƒ‰í•˜ì—¬
    { "íŒŒì¼ID": "ì „ì²´ê²½ë¡œ" } í˜•íƒœì˜ ì§€ë„ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    """
    global VIDEO_PATH_INDEX
    print(f"ğŸ“‚ ì˜ìƒ íŒŒì¼ ì¸ë±ì‹± ì¤‘... ({root_dir})")
    
    count = 0
    # rglob('*')ì€ í•˜ìœ„ í´ë”ê¹Œì§€ ì „ë¶€ ë’¤ì§‘ë‹ˆë‹¤.
    for path in root_dir.rglob("*.mp4"):
        # íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì„ IDë¡œ ì‚¬ìš© (ì˜ˆ: "101650")
        file_id = path.stem 
        VIDEO_PATH_INDEX[file_id] = str(path.resolve())
        count += 1
        
    print(f"âœ… ì´ {count}ê°œì˜ ì˜ìƒ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

def load_gloss_index(csv_path: Path) -> dict:
    """
    ê¸€ë¡œìŠ¤ ì‚¬ì „ì„ ë¡œë“œí•´ ê²€ìƒ‰ìš© ì¸ë±ìŠ¤ë¥¼ ë§Œë“ ë‹¤.
    """
    rows, exact = [], {}
    id_to_word = {}

    # utf-8-sig: BOMì´ ìˆì–´ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        rdr = csv.DictReader(f)
        headers = [h.strip().lower() for h in (rdr.fieldnames or [])]

        def pick(*cands):
            for c in cands:
                if c in headers:
                    return c
            return None

        h_id = pick("gloss_id", "id", "gid")
        h_ko = pick(
            "korean_meanings", "korean", "ko",
            "meaning_ko", "ko_meanings", "korean_meaning",
        )
        if not h_id or not h_ko:
            raise RuntimeError(f"[Gloss] í—¤ë” ê°ì§€ ì‹¤íŒ¨: {headers}")

        for row in rdr:
            gid = (row.get(h_id) or "").strip()
            cell = (row.get(h_ko) or "").strip()
            if not gid or not cell:
                continue

            # '["ê±°ì¹˜","ê±°ì¹˜ì‹"]' ê°™ì€ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ ì•ˆì „ íŒŒì‹±
            try:
                obj = ast.literal_eval(cell)
                if isinstance(obj, (list, tuple)):
                    terms = [str(x) for x in obj]
                else:
                    terms = [str(obj)]
            except Exception:
                terms = [cell]

            if terms:
                id_to_word[gid] = terms[0]

            for term in terms:
                term = _norm(term)
                if not term:
                    continue
                term_ns   = _nospace(term)
                token_cnt = len(term.split())
                char_len  = len(term_ns)
                rows.append({
                    "gid": gid,
                    "term": term,
                    "term_ns": term_ns,
                    "token_cnt": token_cnt,
                    "char_len": char_len,
                })
                # ë™ì¼ term_nsê°€ ì—¬ëŸ¬ gidë¥¼ ê°€ë¦¬í‚¤ë”ë¼ë„ ìµœì´ˆ ë“±ì¥ ìš°ì„ 
                exact.setdefault(term_ns, gid)

    if not rows:
        raise RuntimeError("[Gloss] ì‚¬ì „ì— ìœ íš¨í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì „ë¬¸ìš©ì–´ ìš°ì„ ìˆœìœ„ ì •ë ¬ (cat_1 ê¸°ì¤€)
    rows.sort(key=lambda x: 0 if "ì „ë¬¸ìš©ì–´" in x.get("cat_1", "") else 1)

    print(f"[Gloss] indexed rows={len(rows)}, exact_keys={len(exact)}")
    return {"rows": rows, "exact": exact, "id_to_word": id_to_word}

# [ìˆ˜ì •] blacklist ì¸ì ì¶”ê°€
def map_one_word_to_id(word: str, index: dict, blacklist: list = None) -> str | None:
    if not word or not index:
        return None
    
    # ë¸”ë™ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    if blacklist is None: blacklist = []

    rows, exact = index["rows"], index["exact"]
    w = _first_word(word)
    wns = _nospace(w)
    if not wns: return None

    # 1) ì™„ì „ ì¼ì¹˜ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬)
    gid = exact.get(wns)
    if gid and int(gid) not in blacklist:
        return gid

    # 2) í¬í•¨ í›„ë³´ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬)
    cands = [r for r in rows if wns in r["term_ns"] and int(r["gid"]) not in blacklist]
    if cands:
        cands.sort(key=lambda r: (r["token_cnt"], r["char_len"], r["term"], r["gid"]))
        return cands[0]["gid"]

    # 3) ìœ ì‚¬ë„ ê²€ìƒ‰ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬)
    best_gid, best_sc = None, 0.0
    for r in rows:
        # [ì¤‘ìš”] ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” IDëŠ” ìœ ì‚¬ë„ ê³„ì‚° ëŒ€ìƒì—ì„œ ì œì™¸
        if int(r["gid"]) in blacklist: 
            continue
            
        sc = difflib.SequenceMatcher(None, wns, r["term_ns"]).ratio()
        if sc > best_sc:
            best_sc, best_gid = sc, r["gid"]

    if ALWAYS_RETURN_ID and best_gid:
        return best_gid
    return None

def to_gloss_ids(gloss_list: list[str], index: dict) -> list[str]:
    """ê¸€ë¡œìŠ¤ ë¦¬ìŠ¤íŠ¸ â†’ ì¤‘ë³µ ì œê±°ëœ gloss_id ë¦¬ìŠ¤íŠ¸(ì…ë ¥ ìˆœì„œ ë³´ì¡´)."""
    out, seen = [], set()
    for g in gloss_list or []:
        gid = map_one_word_to_id(g, index)
        if gid and gid not in seen:
            out.append(gid)
            seen.add(gid)
    return out

# [ìˆ˜ì •] ìƒì„¸ ë¡œê·¸(logs)ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ë³€ê²½
def resolve_gloss_token(token_text, original_sentence, rules, db_index):
    final_ids = []
    resolved_logs = [] 
    
    # ID -> ë‹¨ì–´ ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°
    id_map = db_index.get("id_to_word", {})

    blacklist = rules.get("blacklist", [])
    sub_list = rules.get("word_substitution", {}).get(token_text, [token_text])
    
    for sub in sub_list:
        target_ids = []
        method = "unknown"

        # 1. Fixed Mappings
        if sub in rules.get("fixed_mappings", {}):
            target_ids.append(rules["fixed_mappings"][sub])
            method = "fixed_rule"
            
        # 2. Disambiguation
        elif sub in rules.get("disambiguation_rules", {}):
            rule = rules["disambiguation_rules"][sub]
            found = False
            for case in rule["cases"]:
                for kw in case["keywords"]:
                    if kw in original_sentence:
                        target_ids.append(case["target_id"])
                        found = True
                        method = f"context({kw})"
                        break
                if found: break
            if not found:
                target_ids.append(rule["default_id"])
                method = "context_default"

        # 3. DB Search & Decomposition
        else:
            # (A) ì¼ë°˜ ê²€ìƒ‰
            gid = map_one_word_to_id(sub, db_index, blacklist)
            if gid:
                target_ids.append(gid)
                method = "exact/similarity"
            else:
                # (B) ë³µí•©ì–´ ë¶„í•´ ì‹œë„
                decomposed = decompose_compound_word(sub, db_index["exact"])
                if decomposed:
                    for part in decomposed:
                        part_id = map_one_word_to_id(part, db_index, blacklist)
                        if part_id: target_ids.append(part_id)
                    method = f"decomposed({decomposed})"
                else:
                    # (C) ê·¸ë˜ë„ ì—†ìœ¼ë©´ ìœ ì‚¬ë„ ê°•ì œ ê²€ìƒ‰ (ì´ë¯¸ map_one_word_to_idì—ì„œ ìˆ˜í–‰ë¨)
                    pass 

        if target_ids:
            final_ids.extend(target_ids)
            
            # [FIX] IDë¥¼ ì´ìš©í•´ ì‹¤ì œ ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´(Representative Word)ë¥¼ ì°¾ìŒ
            real_words = []
            for tid in target_ids:
                # IDê°€ ìˆ«ìí˜•ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¡°íšŒ
                rw = id_map.get(str(tid), "UnknownID") 
                real_words.append(rw)
            
            resolved_logs.append({
                "token": sub,            # ì…ë ¥ í† í°
                "resolved_word": real_words, # [NEW] ì‹¤ì œ ë§¤í•‘ëœ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
                "ids": target_ids,
                "method": method
            })
            
    return final_ids, resolved_logs

def _paths_from_ids(gloss_ids):
    """
    gloss_id ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” ì§€ë„(VIDEO_PATH_INDEX)ì—ì„œ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    paths, missing = [], []
    for gid in gloss_ids or []:
        gid_str = str(gid) # IDê°€ ìˆ«ìì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìë¡œ ë³€í™˜
        
        if gid_str in VIDEO_PATH_INDEX:
            paths.append(VIDEO_PATH_INDEX[gid_str])
        else:
            missing.append(gid)
            
    if missing:
        print(f"âš ï¸  ë§¤í•‘ ëˆ„ë½ (íŒŒì¼ ì—†ìŒ) gloss_id: {missing}")
    return paths

# [ìˆ˜ì •] ë³µí•©ì–´ ë¶„í•´ í•¨ìˆ˜ ì¶”ê°€
def decompose_compound_word(token, valid_keys):
    if len(token) < 2: return None
    for i in range(1, len(token)):
        part1 = token[:i]
        part2 = token[i:]
        if part1 in valid_keys and part2 in valid_keys:
            return [part1, part2]
    return None


# ==============================================================================
# [SECTION 5] Synthesis (Video Generation)
# í…ìŠ¤íŠ¸ -> ì´ë¯¸ì§€ ì˜ìƒ ë³€í™˜, ê³µë°± ì˜ìƒ ìƒì„±
# ==============================================================================
def get_korean_font(size=80):
    """OSì— ë§ëŠ” í•œêµ­ì–´ í°íŠ¸ ë¡œë“œ ì‹œë„"""
    font_paths = [
        "C:/Windows/Fonts/malgun.ttf",       # Windows
        "/System/Library/Fonts/AppleSDGothicNeo.ttc", # Mac
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf", # Linux
        "AppleGothic.ttf"
    ]
    for path in font_paths:
        try:
            return ImageFont.truetype(path, size)
        except:
            continue
    return ImageFont.load_default()

def generate_image_video(text: str, duration: float = 2.0) -> str:
    """í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì˜ìƒìœ¼ë¡œ ë³€í™˜ (ì „ì²˜ë¦¬ëœ ì˜ìƒ ìŠ¤í™ê³¼ 100% ì¼ì¹˜ì‹œí‚´)"""
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tf:
        img_path = tf.name

    # 1. ê²€ì€ ë°°ê²½ì— í° ê¸€ì”¨ ì´ë¯¸ì§€ ìƒì„±
    width, height = 1280, 720
    img = Image.new('RGB', (width, height), color='black')
    d = ImageDraw.Draw(img)
    
    font = get_korean_font(80)
    
    # í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬
    bbox = d.textbbox((0, 0), text, font=font)
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]
    position = ((width - text_w) / 2, (height - text_h) / 2)
    
    d.text(position, text, font=font, fill="white")
    img.save(img_path)

    # 2. FFmpeg ë³€í™˜ (Code 2ì˜ ìŠ¤í™ì„ ê·¸ëŒ€ë¡œ ì ìš©)
    out_mp4 = img_path.replace(".png", ".mp4")
    
    cmd = [
        "ffmpeg", "-y",
        "-loop", "1", "-i", img_path,    # ì´ë¯¸ì§€ ë£¨í”„ ì…ë ¥
        "-t", str(duration),             # ê¸¸ì´ ì„¤ì •
        
        # [í•µì‹¬] ì½”ë± ë° í¬ë§· ì„¤ì •
        "-c:v", "libx264",               # ì´ë¯¸ì§€ ë³€í™˜ì€ CPU(libx264)ê°€ ë” ì•ˆì •ì /ë¹ ë¥¼ ìˆ˜ ìˆìŒ
        "-preset", "veryfast",           # ìƒì„± ì†ë„ ìµœì í™”
        "-profile:v", "high",            # í”„ë¡œíŒŒì¼: High
        "-pix_fmt", "yuv420p",           # í”½ì…€ í¬ë§·
        
        # [í•µì‹¬] ë³‘í•©ì„ ìœ„í•œ ë¬¼ë¦¬ì  ìŠ¤í™ í†µì¼
        "-r", "30",                      # FPS ê°•ì œ: 30
        "-video_track_timescale", "90000", # íƒ€ì„ë² ì´ìŠ¤: 90000
        "-bf", "2",                      # B-frame: 2
        
        # [í•µì‹¬] ì˜¤ë””ì˜¤ ì œê±° (ê¸°ì¡´ ì˜ìƒì— ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë¯€ë¡œ)
        "-an",
        
        # ë¦¬ì‚¬ì´ì§• (í˜¹ì‹œ ëª¨ë¥¼ í¬ê¸° ì˜¤ë¥˜ ë°©ì§€)
        "-vf", "scale=1280:720",
        
        "-loglevel", "error",
        out_mp4
    ]
    subprocess.run(cmd, check=True)
    
    try: os.remove(img_path)
    except: pass
    
    return out_mp4

def generate_blank_video(duration: float = 1.0) -> str:
    """ê²€ì€ í™”ë©´(Pause) ì˜ìƒ ìƒì„± (ìŠ¤í™ í†µì¼)"""
    with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tf:
        out_mp4 = tf.name
        
    cmd = [
        "ffmpeg", "-y",
        "-f", "lavfi", "-i", f"color=c=black:s=1280x720:d={duration}",
        
        # [í•µì‹¬] ì½”ë± ë° í¬ë§· í†µì¼
        "-c:v", "libx264",
        "-preset", "veryfast",
        "-profile:v", "high",
        "-pix_fmt", "yuv420p",
        
        # [í•µì‹¬] FPS ë° íƒ€ì„ë² ì´ìŠ¤ í†µì¼
        "-r", "30",
        "-video_track_timescale", "90000",
        "-bf", "2",
        
        # ì˜¤ë””ì˜¤ ì œê±°
        "-an",
        
        "-loglevel", "error",
        out_mp4
    ]
    subprocess.run(cmd, check=True)
    return out_mp4


# ==============================================================================
# [SECTION 6] Output (Playback)
# FFmpeg/FFplayë¥¼ ì´ìš©í•œ ì˜ìƒ ì‹œí€€ìŠ¤ ì¬ìƒ
# ==============================================================================
def play_sequence(paths):
    """
    FFmpeg/ffplayë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¬ìƒ.
    """
    if not paths:
        print("âš ï¸ ì¬ìƒí•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    ffmpeg = shutil.which("ffmpeg") or "ffmpeg"
    ffplay = shutil.which("ffplay")  # ìˆìœ¼ë©´ 1ë²ˆ ê²½ë¡œ ì‚¬ìš©

    # 1) ffplay: concat ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ë¡œ ì¬ìƒ
    if ffplay:
        with tempfile.NamedTemporaryFile("w", suffix=".txt", delete=False) as f:
            lst_path = f.name
            for p in paths:
                f.write(f"file '{p}'\n")
        try:
            cmd = [
                ffplay,
                "-autoexit",
                "-hide_banner",
                "-loglevel", "error",
                "-f", "concat",
                "-safe", "0",
                "-i", lst_path,
            ]
            subprocess.run(cmd, check=True)
            return True
        finally:
            try:
                os.remove(lst_path)
            except OSError:
                pass

    # 2) ffmpeg: ì„ì‹œ mp4 ìƒì„± í›„ OS ê¸°ë³¸ í”Œë ˆì´ì–´ë¡œ ì¬ìƒ
    with tempfile.TemporaryDirectory() as td:
        lst = Path(td) / "list.txt"
        out = Path(td) / f"concat_{now_ts()}.mp4"

        # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì‘ì„±
        with open(lst, "w", encoding="utf-8") as f:
            for p in paths:
                f.write(f"file '{p}'\n")

        # (A) ì½”ë± ë™ì¼ ì‹œ ì´ˆê³ ì† copy ì‹œë„
        copy_cmd = [
            ffmpeg, "-y",
            "-f", "concat", "-safe", "0",
            "-i", str(lst),
            "-c", "copy",
            str(out),
        ]
        r = subprocess.run(copy_cmd)

        # (B) ì‹¤íŒ¨í•˜ë©´ ì¬ì¸ì½”ë”©ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ í•©ì„±
        if r.returncode != 0:
            re_cmd = [
                ffmpeg, "-y",
                "-f", "concat", "-safe", "0",
                "-i", str(lst),
                "-vf", "format=yuv420p",
                "-c:v", "libx264", "-crf", "20", "-preset", "veryfast",
                "-c:a", "aac", "-b:a", "128k",
                str(out),
            ]
            subprocess.run(re_cmd, check=True)

        # OS ë³„ ê¸°ë³¸ í”Œë ˆì´ì–´ë¡œ ì—´ê¸°
        if sys.platform == "darwin":          # macOS
            subprocess.Popen(["open", str(out)])
        elif os.name == "nt":                 # Windows
            os.startfile(str(out))
        else:                                 # Linux ë“±
            subprocess.Popen(["xdg-open", str(out)])
        return True

# ... (ê¸°ì¡´ play_sequence í•¨ìˆ˜ ëë‚œ ë’¤ ì•„ë˜ì— ì¶”ê°€) ...

def save_sequence(paths, output_path):
    """
    ì˜ìƒ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸(paths)ë¥¼ ë°›ì•„ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ì—¬ output_pathì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not paths: return

    ffmpeg = shutil.which("ffmpeg") or "ffmpeg"
    
    # 1. ë³‘í•©í•  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± (temp file)
    # Windows ê²½ë¡œ í˜¸í™˜ì„ ìœ„í•´ ë°±ìŠ¬ë˜ì‹œ(\)ë¥¼ ìŠ¬ë˜ì‹œ(/)ë¡œ ë³€ê²½
    with tempfile.NamedTemporaryFile("w", suffix=".txt", delete=False, encoding="utf-8") as f:
        lst_path = f.name
        for p in paths:
            safe_path = str(Path(p).resolve()).replace('\\', '/')
            f.write(f"file '{safe_path}'\n")

    # 2. FFmpeg ë³‘í•© ëª…ë ¹ (ì¬ì¸ì½”ë”© ë°©ì‹: í•´ìƒë„/ì½”ë± í†µì¼ì„±ì„ ìœ„í•´ ì•ˆì „í•¨)
    try:
        cmd = [
            ffmpeg, "-y",
            "-f", "concat", "-safe", "0",
            "-i", lst_path,
            "-c:v", "libx264", "-pix_fmt", "yuv420p",  # í˜¸í™˜ì„± ë†’ì€ í¬ë§·
            "-c:a", "aac",
            "-loglevel", "error",
            str(output_path)
        ]
        subprocess.run(cmd, check=True)
        print(f"ğŸ’¾ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output_path}")

    except Exception as e:
        print(f"âŒ ì˜ìƒ ì €ì¥ ì‹¤íŒ¨: {e}")

    finally:
        # ì„ì‹œ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ
        try: os.remove(lst_path)
        except: pass


# ==============================================================================
# [SECTION 7] Main Execution
# íŒŒì´í”„ë¼ì¸ ì¡°ë¦½ ë° ì‹¤í–‰ ë£¨í”„
# ==============================================================================
def main():
    # 0) rules.json ë¡œë“œ (ë£° ì—”ì§„ìš©)
    rules_json = {}
    if RULES_JSON_PATH.exists():
        with open(RULES_JSON_PATH, 'r', encoding='utf-8') as f:
            rules_json = json.load(f)
        print(f"[Rules] Loaded rules.json from {RULES_JSON_PATH}")
    else:
        print(f"âš ï¸ [Warning] rules.json not found at {RULES_JSON_PATH}. Rule engine disabled.")
    # [FIX] ì˜ìƒ íŒŒì¼ ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ ì¶”ê°€
    # ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ìœ„ í´ë”(fi, li)ì˜ ëª¨ë“  mp4 ìœ„ì¹˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    build_video_index(GLOSS_MP4_DIR)

    # 1) ê¸€ë¡œìŠ¤ ì‚¬ì „ ë¡œë“œ
    index = load_gloss_index(GLOSS_DICT_PATH)

    # 2) Gemini ëª¨ë¸ ì´ˆê¸°í™”
    model = build_gemini()

    # 3) Whisper ëª¨ë¸ ë¡œë“œ
    print("[Whisper] loading:", WHISPER_MODEL_NAME)
    wmodel = whisper.load_model(WHISPER_MODEL_NAME)

    # 4) ì˜¤ë””ì˜¤ ì¥ì¹˜ í™•ì¸
    global sd_stream
    list_devices()
    
    print("\n" + "="*60)
    print("ğŸ™ï¸  [Push-to-Talk ëª¨ë“œ] Enterë¥¼ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘/ì¢…ë£Œí•©ë‹ˆë‹¤.")
    print("="*60)

    snap_idx = 0

    while True:
        # --- [ì˜¤ë””ì˜¤ ì œì–´: Push-to-Talk] ---
        try:
            # 1. ëŒ€ê¸° (ë…¹ìŒ ì‹œì‘ íŠ¸ë¦¬ê±°)
            input("\n[Ready] Enterë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤ >>> ")
            
            # 2. ìŠ¤íŠ¸ë¦¼ ì—´ê¸° ë° ë…¹ìŒ ì‹œì‘
            if sd_stream: 
                sd_stream.stop(); sd_stream.close()
            
            sd_stream = open_input_stream()
            sd_stream.start()
            
            # ë²„í¼ ì´ˆê¸°í™” (ì´ì „ ì”ì—¬ ë°ì´í„° ì‚­ì œ)
            with frames_lock:
                frames.clear()
                
            print("   ğŸ”´ ë…¹ìŒ ì¤‘... (ë§ì”€í•˜ì‹  ë’¤ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”)")
            
            # 3. ë…¹ìŒ ì¤‘ (ì¢…ë£Œ íŠ¸ë¦¬ê±° ëŒ€ê¸°)
            input() 
            
            # 4. ë…¹ìŒ ì¤‘ë‹¨ ë° ë°ì´í„° í™•ë³´
            sd_stream.stop()
            with frames_lock:
                blob = b"".join(frames)
            sd_stream.close()
            
            if not blob:
                print("[Info] ë…¹ìŒëœ ì†Œë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # --- [ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘] ---
            ts = now_ts()
            base = OUT_DIR / f"snapshot_{ts}_{snap_idx + 1:02d}"

            # 5-1) WAV ì €ì¥
            wav_path = str(base) + ".wav"
            with wave.open(wav_path, "wb") as wf:
                wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(ACTUAL_RATE)
                wf.writeframes(blob)
            
            # 5-2) Whisper STT
            print("â³ ì „ì‚¬ ë° ë¶„ì„ ì¤‘...")
            res = wmodel.transcribe(wav_path, language=WHISPER_LANG)
            stt_text = _norm(res.get("text") or "")
            print(f"[STT] \"{stt_text}\"")
            
            # 5-3) Gemini -> í† í°(JSON) ì¶”ì¶œ
            # tokens ì˜ˆ: [{"text":"ë§Œ 18ì„¸", "type":"image"}, {"text":"ê°€ì…", "type":"gloss"}]
            tokens = extract_glosses(stt_text, model)
            print(f"[Tokens] {tokens}")

            # 5-4) [ë©€í‹°ëª¨ë‹¬ í•©ì„±] ë° [ìƒì„¸ ë¹„êµ ë¡œê¹…]
            play_queue = []
            debug_logs = []
            
            print("\n" + "="*30 + " [í† í° ë§¤í•‘ ìƒì„¸ ë¶„ì„] " + "="*30)
            print(f"ğŸ“„ ì›ë³¸ STT: {stt_text}")
            print("-" * 110)
            # í—¤ë” ì¶œë ¥ (ê°€ë…ì„± í™•ë³´)
            print(f"{'NLP Token':<15} | {'Resolved Tokens':<20} | {'Method':<18} | {'Video IDs':<15} | {'Note'}")
            print("-" * 110)

            for token in tokens:
                dtype = token.get("type", "gloss")
                text = token.get("text", "")
                
                if not text and dtype != "pause": continue

                token_log = {
                    "nlp_token": text,
                    "type": dtype,
                    "final_mapping": {}
                }

                # [Case 1] ìˆ˜ì–´(Gloss) ì²˜ë¦¬
                if dtype == "gloss":
                    # ids: ìµœì¢… ë§¤í•‘ëœ ì˜ìƒ ID ë¦¬ìŠ¤íŠ¸
                    # logs: ì•Œê³ ë¦¬ì¦˜ ê±°ì¹œ ì„¸ë¶€ ë‚´ì—­ [{'token': 'ìš°ëŒ€', 'method': '...'}, {'token': 'ê¸ˆë¦¬' ...}]
                    ids, logs = resolve_gloss_token(text, stt_text, rules_json, index)
                    
                    if ids:
                        # (A) ë§¤ì¹­ ì„±ê³µ
                        paths = _paths_from_ids(ids)
                        play_queue.extend(paths)
                        
                        # ë¹„êµ ì¶œë ¥ì„ ìœ„í•œ ë°ì´í„° ê°€ê³µ
                                   
                        ids_str = ", ".join(map(str, ids))          # "10123, 10456"
                        resolved_words_flat = []
                        for l in logs:
                            resolved_words_flat.extend(l.get('resolved_word', []))
                        
                        resolved_str = ", ".join(resolved_words_flat) # "ë‘˜, ë¯¸ì•ˆí•˜ë‹¤" ì²˜ëŸ¼ ì¶œë ¥ë¨
                        
                        # ë°©ì‹ì€ ì²« ë²ˆì§¸ ê²ƒ í˜¹ì€ ë³µí•©ì ì´ë©´ 'mixed'
                        method_str = logs[0]['method'] if len(logs) == 1 else "compound/mixed"
                        if "decomposed" in str(logs): method_str = "decomposed"

                        # íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¸ìš©)
                        file_names = [Path(p).name for p in paths]
                        
                        # [í•µì‹¬] í•œ ì¤„ì— ë¹„êµ ì¶œë ¥
                        print(f"{text:<15} | {resolved_str:<20} | {method_str:<18} | {ids_str:<15} | {len(ids)} clips")
                        
                        # JSON ë¡œê·¸ ì €ì¥ êµ¬ì¡°
                        token_log["final_mapping"] = {
                            "status": "success",
                            "resolved_tokens": resolved_words_flat,
                            "video_ids": ids,
                            "method": method_str,
                            "files": file_names
                        }

                    else:
                        # (B) ë§¤ì¹­ ì‹¤íŒ¨ -> í…ìŠ¤íŠ¸ ì´ë¯¸ì§€(Fallback)
                        print(f"{text:<15} | {'(IMAGE TEXT)':<20} | {'FALLBACK':<18} | {'-':<15} | Gen Image")
                        
                        calc_duration = max(1.5, len(text) * 0.5)
                        p = generate_image_video(text, duration=calc_duration)
                        play_queue.append(p)
                        
                        token_log["final_mapping"] = {
                            "status": "fallback",
                            "resolved_tokens": [text],
                            "method": "text_image_generation"
                        }

                # [Case 2] ìˆ«ì/ì´ë¯¸ì§€ ì²˜ë¦¬
                elif dtype == "image":
                    print(f"{text:<15} | {'(IMAGE)':<20} | {'LLM_DIRECT':<18} | {'-':<15} | Gen Image")
                    p = generate_image_video(text, duration=2.0)
                    play_queue.append(p)
                    token_log["final_mapping"] = {"status": "image", "method": "llm_directive"}

                # [Case 3] íœ´ì§€(Pause) ì²˜ë¦¬
                elif dtype == "pause":
                    print(f"{'PAUSE':<15} | {'(BLANK)':<20} | {'LLM_DIRECT':<18} | {'-':<15} | 1.0 sec")
                    p = generate_blank_video(duration=1.0)
                    play_queue.append(p)
                    token_log["final_mapping"] = {"status": "pause", "duration": 1.0}
                
                debug_logs.append(token_log)

            print("-" * 110 + "\n")

            # [í†µí•©] ë¡œê·¸ ë°ì´í„° êµ¬ì„± (ì•„ì§ ì €ì¥ ì•ˆ í•¨)
            log_data = {
                "timestamp": ts,
                "stt_raw": stt_text,
                "nlp_tokens": tokens,
                "processing_detail": debug_logs, # ìƒì„¸ ë¡œê·¸
                "play_queue": play_queue         # ì¬ìƒ ëª©ë¡
            }

            # 5-5) ìµœì¢… ì¬ìƒ ë° ì˜ìƒ íŒŒì¼ ì €ì¥
            if play_queue:
                print(f"â–¶ï¸  ì´ {len(play_queue)}ê°œ í´ë¦½ ì¬ìƒ ì‹œì‘")
                
                # (1) ì¬ìƒ
                play_sequence(play_queue)

                # (2) ì˜ìƒ íŒŒì¼ ì €ì¥
                save_filename = VIDEO_OUT_DIR / f"{ts}.mp4" 
                print(f"ğŸ’¾ ì˜ìƒì„ ì €ì¥í•©ë‹ˆë‹¤... -> {save_filename}")
                save_sequence(play_queue, save_filename)
                
                # ì˜ìƒ ì €ì¥ ê²½ë¡œë„ ë¡œê·¸ì— ì¶”ê°€
                log_data["saved_video_path"] = str(save_filename)

            else:
                print("âš ï¸ ì¬ìƒí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                log_data["saved_video_path"] = None

            # 5-6) ë¡œê·¸ íŒŒì¼ ì €ì¥ (JSON) - [ì—¬ê¸°ì„œ ë”± í•œ ë²ˆë§Œ ì €ì¥]
            json_path = str(base) + ".json"
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)
            print(f"[Log Saved] {json_path}")
            
            snap_idx += 1

        except KeyboardInterrupt:
            print("\n[ì¢…ë£Œ] í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\n[Error] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

    # ì¢…ë£Œ ì •ë¦¬
    if sd_stream:
        try: sd_stream.stop(); sd_stream.close()
        except: pass


if __name__ == "__main__":
    main()